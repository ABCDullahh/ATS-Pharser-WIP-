{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320b6f6d74a24e70b1a5fb2cba303850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf, .docx', description='Upload Resume')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pdfplumber\n",
    "# from docx import Document\n",
    "# import re\n",
    "# import spacy\n",
    "# from IPython.display import display\n",
    "# import ipywidgets as widgets\n",
    "# from ipywidgets import FileUpload\n",
    "\n",
    "# # Memuat model NLP Spacy untuk ekstraksi entitas\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# # Fungsi untuk membaca teks dari file PDF\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     text = \"\"\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page in pdf.pages:\n",
    "#             text += page.extract_text()\n",
    "#     return text\n",
    "\n",
    "# # Fungsi untuk membaca teks dari file .docx\n",
    "# def extract_text_from_docx(docx_path):\n",
    "#     doc = Document(docx_path)\n",
    "#     return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# # Fungsi untuk ekstraksi email dari teks\n",
    "# def extract_email(text):\n",
    "#     email = re.search(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', text)\n",
    "#     return email.group(0) if email else None\n",
    "\n",
    "# # Fungsi untuk ekstraksi nomor telepon dari teks\n",
    "# def extract_phone(text):\n",
    "#     # Memperbaiki regex agar mendukung format telepon internasional, spasi, atau tanda tambahan\n",
    "#     phone = re.search(r'\\+?\\d{1,4}[r'\\s'.-]?\\(?\\d{1,3}\\)?[r'\\s'.-]?\\d{1,4}[r'\\s'.-]?\\d{1,4}[r'\\s'.-]?\\d{1,9}', text)\n",
    "#     return phone.group(0) if phone else None\n",
    "\n",
    "# # Fungsi untuk ekstraksi nama dari teks menggunakan Spacy\n",
    "# def extract_name(text):\n",
    "#     doc = nlp(text)\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ == \"PERSON\":\n",
    "#             return ent.text\n",
    "#     return None\n",
    "\n",
    "# # Fungsi untuk ekstraksi LinkedIn dan GitHub\n",
    "# def extract_linkedin(text):\n",
    "#     linkedin = re.search(r'linkedin\\.com/in/[\\w-]+', text)\n",
    "#     return linkedin.group(0) if linkedin else None\n",
    "\n",
    "# def extract_github(text):\n",
    "#     github = re.search(r'github\\.com/[\\w-]+', text)\n",
    "#     return github.group(0) if github else None\n",
    "\n",
    "# # Fungsi untuk ekstraksi pengalaman kerja yang lebih baik\n",
    "# def extract_experience(text):\n",
    "#     # Memperluas pola untuk mencari posisi dan durasi pekerjaan\n",
    "#     experience = re.findall(r\"(?:\\b(?:work|experience|employment|job|career|position)\\b.*?:r'\\s'*)(.*?)(?:\\n|$)\", text, re.IGNORECASE)\n",
    "#     return experience if experience else [\"Experience not found\"]\n",
    "\n",
    "# # Fungsi untuk ekstraksi pendidikan yang lebih baik, termasuk nama universitas dan IPK\n",
    "# def extract_education(text):\n",
    "#     # Cari informasi pendidikan menggunakan kata kunci dan juga GPA/IPK\n",
    "#     education = re.findall(r\"(?:\\b(?:education|degree|university|college|institute)\\b.*?:r'\\s'*)(.*?)(?:\\n|$)\", text, re.IGNORECASE)\n",
    "#     gpa = re.search(r\"(\\bGPA\\b|\\bIPK\\b).{0,5}(\\d\\.\\d+)\", text, re.IGNORECASE)\n",
    "#     gpa_score = gpa.group(2) if gpa else \"GPA not found\"\n",
    "    \n",
    "#     education_info = education if education else [\"Education not found\"]\n",
    "#     education_info.append(f\"GPA: {gpa_score}\")\n",
    "    \n",
    "#     return education_info\n",
    "\n",
    "# # Fungsi untuk ekstraksi keterampilan dengan deteksi yang lebih luas\n",
    "# def extract_skills(text):\n",
    "#     # Memperluas pencarian kata kunci untuk keterampilan\n",
    "#     skills = re.findall(r\"(?:\\b(?:skills|technologies|languages|tools|expertise|competencies)\\b.*?:r'\\s'*)(.*?)(?:\\n|$)\", text, re.IGNORECASE)\n",
    "#     return skills if skills else [\"Skills not found\"]\n",
    "\n",
    "# # Fungsi utama untuk parsing resume\n",
    "# def parse_resume(file_path, file_type=\"pdf\"):\n",
    "#     text = extract_text_from_pdf(file_path) if file_type == \"pdf\" else extract_text_from_docx(file_path)\n",
    "    \n",
    "#     parsed_data = {\n",
    "#         \"name\": extract_name(text),\n",
    "#         \"email\": extract_email(text),\n",
    "#         \"phone\": extract_phone(text),\n",
    "#         \"linkedin\": extract_linkedin(text),\n",
    "#         \"github\": extract_github(text),\n",
    "#         \"experience\": extract_experience(text),\n",
    "#         \"education\": extract_education(text),\n",
    "#         \"skills\": extract_skills(text)\n",
    "#     }\n",
    "#     return parsed_data\n",
    "\n",
    "# # Fungsi untuk menghitung keberhasilan parsing\n",
    "# def calculate_parsing_success(parsed_data):\n",
    "#     fields = ['name', 'email', 'phone', 'linkedin', 'github', 'experience', 'education', 'skills']\n",
    "#     filled_fields = sum([1 for field in fields if parsed_data.get(field) is not None])\n",
    "#     success_rate = (filled_fields / len(fields)) * 100\n",
    "#     return success_rate\n",
    "\n",
    "# # Fungsi untuk menampilkan hasil parsing\n",
    "# def display_parsing_results(parsed_data):\n",
    "#     print(\"\\nParsed Data:\")\n",
    "#     for key, value in parsed_data.items():\n",
    "#         if isinstance(value, list):\n",
    "#             print(f\"{key.capitalize()}:\")\n",
    "#             for item in value:\n",
    "#                 print(f\"  - {item}\")\n",
    "#         else:\n",
    "#             print(f\"{key.capitalize()}: {value}\")\n",
    "    \n",
    "#     success_rate = calculate_parsing_success(parsed_data)\n",
    "#     print(f\"\\nParsing Success Rate: {success_rate:.2f}%\")\n",
    "\n",
    "# # Fungsi untuk mengunggah file dan menampilkan hasil parsing\n",
    "# def on_file_upload(change):\n",
    "#     try:\n",
    "#         # Mendapatkan file yang diunggah\n",
    "#         file_upload = change['owner']\n",
    "        \n",
    "#         if not file_upload.value:  # Check if any file was uploaded\n",
    "#             print(\"No file uploaded\")\n",
    "#             return\n",
    "            \n",
    "#         # Get the first uploaded file directly from the value tuple\n",
    "#         uploaded_file = file_upload.value[0]  # Access first element of the tuple\n",
    "        \n",
    "#         # Nama file dan konten\n",
    "#         file_name = uploaded_file.name  # Use .name attribute directly\n",
    "#         file_content = uploaded_file.content  # Use .content attribute directly\n",
    "#         file_path = f\"./{file_name}\"\n",
    "        \n",
    "#         # Menyimpan file yang diunggah\n",
    "#         with open(file_path, \"wb\") as f:\n",
    "#             f.write(file_content)\n",
    "        \n",
    "#         # Tentukan tipe file (pdf atau docx)\n",
    "#         file_type = \"pdf\" if file_name.lower().endswith(\".pdf\") else \"docx\"\n",
    "        \n",
    "#         # Melakukan parsing file\n",
    "#         parsed_data = parse_resume(file_path, file_type)\n",
    "        \n",
    "#         # Menampilkan hasil parsing\n",
    "#         display_parsing_results(parsed_data)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing file: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()  # This will print the full error traceback for debugging\n",
    "\n",
    "# # Membuat widget untuk unggah file\n",
    "# file_upload_widget = FileUpload(\n",
    "#     accept='.pdf, .docx',\n",
    "#     multiple=False,\n",
    "#     description='Upload Resume'\n",
    "# )\n",
    "# file_upload_widget.observe(on_file_upload, names='value')\n",
    "# display(file_upload_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdfplumber\n",
    "# from docx import Document\n",
    "# import re\n",
    "# import spacy\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# import os\n",
    "# from typing import Dict, List, Optional, Tuple\n",
    "# import csv\n",
    "# from dateutil.parser import parse\n",
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# # Download required NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# # Load spaCy model\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# class ResumeParser:\n",
    "#     def __init__(self):\n",
    "#         # Initialize common skills database\n",
    "#         self.technical_skills = set([\n",
    "#             \"python\", \"java\", \"javascript\", \"html\", \"css\", \"sql\", \"aws\", \"docker\",\n",
    "#             \"kubernetes\", \"react\", \"angular\", \"vue\", \"node.js\", \"spring\", \"django\",\n",
    "#             \"flask\", \"tensorflow\", \"pytorch\", \"machine learning\", \"ai\", \"git\"\n",
    "#         ])\n",
    "        \n",
    "#         self.soft_skills = set([\n",
    "#             \"leadership\", \"communication\", \"teamwork\", \"problem solving\",\n",
    "#             \"analytical\", \"project management\", \"time management\", \"agile\",\n",
    "#             \"scrum\", \"presentation\", \"negotiation\", \"strategic thinking\"\n",
    "#         ])\n",
    "        \n",
    "#         # Initialize certification patterns\n",
    "#         self.certification_patterns = [\n",
    "#             r\"(certified|certificate|certification|qualified|accredited)\",\n",
    "#             r\"(AWS|Microsoft|Google|Oracle|Cisco|CompTIA|PMI|ITIL|PMP|CISSP|CEH)\"\n",
    "#         ]\n",
    "        \n",
    "#         # Initialize education keywords\n",
    "#         self.education_keywords = [\n",
    "#             \"bachelor\", \"master\", \"phd\", \"doctorate\", \"bs\", \"ba\", \"ms\", \"ma\", \n",
    "#             \"btech\", \"mtech\", \"bsc\", \"msc\", \"diploma\"\n",
    "#         ]\n",
    "\n",
    "#     def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "#         \"\"\"Extract text from PDF with enhanced error handling and formatting.\"\"\"\n",
    "#         try:\n",
    "#             text = \"\"\n",
    "#             with pdfplumber.open(pdf_path) as pdf:\n",
    "#                 for page in pdf.pages:\n",
    "#                     text += page.extract_text() + \"\\n\"\n",
    "#             return self._clean_text(text)\n",
    "#         except Exception as e:\n",
    "#             raise Exception(f\"Error extracting text from PDF: {str(e)}\")\n",
    "\n",
    "#     def extract_text_from_docx(self, docx_path: str) -> str:\n",
    "#         \"\"\"Extract text from DOCX with enhanced formatting preservation.\"\"\"\n",
    "#         try:\n",
    "#             doc = Document(docx_path)\n",
    "#             text = \"\"\n",
    "#             for para in doc.paragraphs:\n",
    "#                 text += para.text + \"\\n\"\n",
    "#             return self._clean_text(text)\n",
    "#         except Exception as e:\n",
    "#             raise Exception(f\"Error extracting text from DOCX: {str(e)}\")\n",
    "\n",
    "#     def _clean_text(self, text: str) -> str:\n",
    "#         \"\"\"Clean and normalize extracted text.\"\"\"\n",
    "#         text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n",
    "#         text = re.sub(r'[^\\x00-\\x7F]+', '', text)  # Remove non-ASCII characters\n",
    "#         return text.strip()\n",
    "\n",
    "#     def extract_contact_info(self, text: str) -> Dict[str, Optional[str]]:\n",
    "#         \"\"\"Extract comprehensive contact information.\"\"\"\n",
    "#         contact_info = {\n",
    "#             \"name\": self._extract_name(text),\n",
    "#             \"email\": self._extract_email(text),\n",
    "#             \"phone\": self._extract_phone(text),\n",
    "#             \"location\": self._extract_location(text),\n",
    "#             \"linkedin\": self._extract_linkedin(text),\n",
    "#             \"github\": self._extract_github(text),\n",
    "#             \"portfolio\": self._extract_portfolio(text)\n",
    "#         }\n",
    "#         return contact_info\n",
    "\n",
    "#     def _extract_name(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Enhanced name extraction using NLP and heuristics.\"\"\"\n",
    "#         doc = nlp(text[:1000])  # Process first 1000 chars for efficiency\n",
    "        \n",
    "#         # First try to find name in header\n",
    "#         first_lines = text.split('\\n')[:3]\n",
    "#         for line in first_lines:\n",
    "#             doc_line = nlp(line)\n",
    "#             for ent in doc_line.ents:\n",
    "#                 if ent.label_ == \"PERSON\":\n",
    "#                     return ent.text\n",
    "\n",
    "#         # Fallback to first PERSON entity in document\n",
    "#         for ent in doc.ents:\n",
    "#             if ent.label_ == \"PERSON\":\n",
    "#                 return ent.text\n",
    "        \n",
    "#         return None\n",
    "\n",
    "#     def _extract_email(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract email with support for various formats.\"\"\"\n",
    "#         email_pattern = r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b'\n",
    "#         match = re.search(email_pattern, text)\n",
    "#         return match.group(0) if match else None\n",
    "\n",
    "#     def _extract_phone(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract phone numbers in various international formats.\"\"\"\n",
    "#         phone_patterns = [\n",
    "#             r'\\+?\\d{1,4}[-.\\s]?\\(?\\d{1,4}\\)?[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,9}',\n",
    "#             r'\\(\\d{3}\\)[-.\\s]?\\d{3}[-.\\s]?\\d{4}',\n",
    "#             r'\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in phone_patterns:\n",
    "#             match = re.search(pattern, text)\n",
    "#             if match:\n",
    "#                 return self._standardize_phone(match.group(0))\n",
    "#         return None\n",
    "\n",
    "#     def _standardize_phone(self, phone: str) -> str:\n",
    "#         \"\"\"Standardize phone number format.\"\"\"\n",
    "#         digits = re.sub(r'\\D', '', phone)\n",
    "#         if len(digits) == 10:\n",
    "#             return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n",
    "#         return phone\n",
    "\n",
    "#     def _extract_location(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract location information using NLP.\"\"\"\n",
    "#         doc = nlp(text)\n",
    "#         for ent in doc.ents:\n",
    "#             if ent.label_ in [\"GPE\", \"LOC\"]:\n",
    "#                 return ent.text\n",
    "#         return None\n",
    "\n",
    "#     def _extract_linkedin(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract LinkedIn profile URL.\"\"\"\n",
    "#         patterns = [\n",
    "#             r'linkedin\\.com/in/[\\w-]+',\n",
    "#             r'linkedin\\.com/profile/[\\w-]+',\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in patterns:\n",
    "#             match = re.search(pattern, text.lower())\n",
    "#             if match:\n",
    "#                 return \"https://www.\" + match.group(0)\n",
    "#         return None\n",
    "\n",
    "#     def _extract_github(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract GitHub profile URL.\"\"\"\n",
    "#         match = re.search(r'github\\.com/[\\w-]+', text.lower())\n",
    "#         return \"https://www.\" + match.group(0) if match else None\n",
    "\n",
    "#     def _extract_portfolio(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract portfolio or personal website URL.\"\"\"\n",
    "#         portfolio_patterns = [\n",
    "#             r'portfolio:?\\s*(https?://\\S+)',\n",
    "#             r'website:?\\s*(https?://\\S+)',\n",
    "#             r'(https?://\\S+\\.(?:com|io|dev|me))'\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in portfolio_patterns:\n",
    "#             match = re.search(pattern, text, re.IGNORECASE)\n",
    "#             if match:\n",
    "#                 return match.group(1)\n",
    "#         return None\n",
    "\n",
    "#     def extract_experience(self, text: str) -> List[Dict[str, str]]:\n",
    "#         \"\"\"Extract detailed work experience with dates, companies, and responsibilities.\"\"\"\n",
    "#         experience_sections = self._find_experience_sections(text)\n",
    "#         experiences = []\n",
    "        \n",
    "#         for section in experience_sections:\n",
    "#             experience_entries = self._parse_experience_entries(section)\n",
    "#             experiences.extend(experience_entries)\n",
    "            \n",
    "#         return experiences\n",
    "\n",
    "#     def _find_experience_sections(self, text: str) -> List[str]:\n",
    "#         \"\"\"Identify experience sections in the text.\"\"\"\n",
    "#         experience_headers = [\n",
    "#             r\"EXPERIENCE\",\n",
    "#             r\"WORK EXPERIENCE\",\n",
    "#             r\"PROFESSIONAL EXPERIENCE\",\n",
    "#             r\"EMPLOYMENT HISTORY\",\n",
    "#             r\"WORK HISTORY\"\n",
    "#         ]\n",
    "        \n",
    "#         sections = []\n",
    "#         lines = text.split('\\n')\n",
    "#         collecting = False\n",
    "#         current_section = []\n",
    "        \n",
    "#         for line in lines:\n",
    "#             if any(re.search(header, line, re.IGNORECASE) for header in experience_headers):\n",
    "#                 if collecting:\n",
    "#                     sections.append('\\n'.join(current_section))\n",
    "#                 collecting = True\n",
    "#                 current_section = []\n",
    "#             elif collecting and line.strip():\n",
    "#                 if any(header in line.upper() for header in [\"EDUCATION\", \"SKILLS\", \"CERTIFICATIONS\"]):\n",
    "#                     collecting = False\n",
    "#                     sections.append('\\n'.join(current_section))\n",
    "#                 else:\n",
    "#                     current_section.append(line)\n",
    "                    \n",
    "#         if collecting and current_section:\n",
    "#             sections.append('\\n'.join(current_section))\n",
    "            \n",
    "#         return sections\n",
    "\n",
    "#     def _parse_experience_entries(self, section: str) -> List[Dict[str, str]]:\n",
    "#         \"\"\"Parse individual experience entries.\"\"\"\n",
    "#         entries = []\n",
    "#         lines = section.split('\\n')\n",
    "#         current_entry = {}\n",
    "        \n",
    "#         date_pattern = r'(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}\\b)'\n",
    "        \n",
    "#         for line in lines:\n",
    "#             # Try to identify start of new entry\n",
    "#             dates = re.findall(date_pattern, line)\n",
    "#             if dates:\n",
    "#                 if current_entry:\n",
    "#                     entries.append(current_entry)\n",
    "#                 current_entry = {\n",
    "#                     \"company\": self._extract_company(line),\n",
    "#                     \"title\": self._extract_job_title(line),\n",
    "#                     \"dates\": self._parse_dates(line),\n",
    "#                     \"responsibilities\": []\n",
    "#                 }\n",
    "#             elif current_entry and line.strip():\n",
    "#                 current_entry[\"responsibilities\"].append(line.strip())\n",
    "        \n",
    "#         if current_entry:\n",
    "#             entries.append(current_entry)\n",
    "            \n",
    "#         return entries\n",
    "\n",
    "#     def _extract_company(self, line: str) -> str:\n",
    "#         \"\"\"Extract company name from line.\"\"\"\n",
    "#         # Remove dates and common job titles\n",
    "#         cleaned = re.sub(r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}\\b', '', line)\n",
    "#         cleaned = re.sub(r'\\b(?:Senior|Junior|Lead|Principal|Software|Engineer|Developer|Manager|Director)\\b', '', cleaned)\n",
    "        \n",
    "#         # Company names often appear in CAPS or after '@' or 'at'\n",
    "#         company_patterns = [\n",
    "#             r'@\\s*([A-Z][A-Za-z\\s&]+)',\n",
    "#             r'at\\s+([A-Z][A-Za-z\\s&]+)',\n",
    "#             r'([A-Z][A-Z\\s&]+[A-Z])'\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in company_patterns:\n",
    "#             match = re.search(pattern, cleaned)\n",
    "#             if match:\n",
    "#                 return match.group(1).strip()\n",
    "        \n",
    "#         return \"Unknown Company\"\n",
    "\n",
    "#     def _extract_job_title(self, line: str) -> str:\n",
    "#         \"\"\"Extract job title from line.\"\"\"\n",
    "#         title_patterns = [\n",
    "#             r'\\b(?:Senior|Junior|Lead|Principal|Software|Engineer|Developer|Manager|Director|Architect)(?:\\s+[A-Za-z]+)*\\b',\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in title_patterns:\n",
    "#             match = re.search(pattern, line)\n",
    "#             if match:\n",
    "#                 return match.group(0)\n",
    "        \n",
    "#         return \"Unknown Position\"\n",
    "\n",
    "#     def _parse_dates(self, line: str) -> Dict[str, str]:\n",
    "#         \"\"\"Parse start and end dates from line.\"\"\"\n",
    "#         date_pattern = r'(\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}\\b)'\n",
    "#         dates = re.findall(date_pattern, line)\n",
    "        \n",
    "#         result = {\n",
    "#             \"start\": dates[0] if dates else \"Unknown\",\n",
    "#             \"end\": dates[1] if len(dates) > 1 else \"Present\"\n",
    "#         }\n",
    "        \n",
    "#         return result\n",
    "\n",
    "#     def extract_education(self, text: str) -> List[Dict[str, str]]:\n",
    "#         \"\"\"Extract comprehensive education information.\"\"\"\n",
    "#         education_sections = self._find_education_sections(text)\n",
    "#         education_entries = []\n",
    "        \n",
    "#         for section in education_sections:\n",
    "#             entries = self._parse_education_entries(section)\n",
    "#             education_entries.extend(entries)\n",
    "            \n",
    "#         return education_entries\n",
    "\n",
    "#     def _find_education_sections(self, text: str) -> List[str]:\n",
    "#         \"\"\"Identify education sections in the text.\"\"\"\n",
    "#         education_headers = [\n",
    "#             r\"EDUCATION\",\n",
    "#             r\"ACADEMIC BACKGROUND\",\n",
    "#             r\"ACADEMIC HISTORY\",\n",
    "#             r\"EDUCATIONAL QUALIFICATIONS\"\n",
    "#         ]\n",
    "        \n",
    "#         sections = []\n",
    "#         lines = text.split('\\n')\n",
    "#         collecting = False\n",
    "#         current_section = []\n",
    "        \n",
    "#         for line in lines:\n",
    "#             if any(re.search(header, line, re.IGNORECASE) for header in education_headers):\n",
    "#                 if collecting:\n",
    "#                     sections.append('\\n'.join(current_section))\n",
    "#                 collecting = True\n",
    "#                 current_section = []\n",
    "#             elif collecting and line.strip():\n",
    "#                 if any(header in line.upper() for header in [\"EXPERIENCE\", \"SKILLS\", \"CERTIFICATIONS\"]):\n",
    "#                     collecting = False\n",
    "#                     sections.append('\\n'.join(current_section))\n",
    "#                 else:\n",
    "#                     current_section.append(line)\n",
    "                    \n",
    "#         if collecting and current_section:\n",
    "#             sections.append('\\n'.join(current_section))\n",
    "            \n",
    "#         return sections\n",
    "\n",
    "#     def _parse_education_entries(self, section: str) -> List[Dict[str, str]]:\n",
    "#         \"\"\"Parse individual education entries.\"\"\"\n",
    "#         entries = []\n",
    "#         current_entry = {}\n",
    "        \n",
    "#         # Split into paragraphs\n",
    "#         paragraphs = section.split('\\n\\n')\n",
    "        \n",
    "#         for para in paragraphs:\n",
    "#             if any(keyword in para.lower() for keyword in self.education_keywords):\n",
    "#                 if current_entry:\n",
    "#                     entries.append(current_entry)\n",
    "#                 current_entry = {\n",
    "#                     \"degree\": self._extract_degree(para),\n",
    "#                     \"institution\": self._extract_institution(para),\n",
    "#                     \"dates\": self._parse_education_dates(para),\n",
    "#                     \"gpa\": self._extract_gpa(para),\n",
    "#                     \"honors\": self._extract_honors(para),\n",
    "#                     \"major\": self._extract_major(para)\n",
    "#                 }\n",
    "        \n",
    "#         if current_entry:\n",
    "#             entries.append(current_entry)\n",
    "            \n",
    "#         return entries\n",
    "\n",
    "#     def _extract_degree(self, text: str) -> str:\n",
    "#         \"\"\"Extract degree information.\"\"\"\n",
    "#         degree_patterns = [\n",
    "#             r\"(?:Bachelor|Master|Doctor|PhD|BSc|BA|MS|MA|MBA|PhD)(?:\\s+of\\s+)?(?:Science|Arts|Engineering|Technology|Business Administration)?\",\n",
    "#             r\"B\\.[A-Za-z.]+\",\n",
    "#             r\"M\\.[A-Za-z.]+\",\n",
    "#             r\"Ph\\.D\\.\"\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in degree_patterns:\n",
    "#             match = re.search(pattern, text, re.IGNORECASE)\n",
    "#             if match:\n",
    "#                 return match.group(0)\n",
    "#         return \"Degree not specified\"\n",
    "#     def _extract_institution(self, text: str) -> str:\n",
    "#         \"\"\"Extract institution name.\"\"\"\n",
    "#         # Look for patterns like \"University of X\" or capitalized words\n",
    "#         inst_patterns = [\n",
    "#             r\"(?:University|College|Institute|School) of [A-Z][A-Za-z\\s]+\",\n",
    "#             r\"[A-Z][A-Za-z]+ (?:University|College|Institute|School)\",\n",
    "#             r\"[A-Z][A-Z\\s]+ (?:UNIVERSITY|COLLEGE|INSTITUTE|SCHOOL)\"\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in inst_patterns:\n",
    "#             match = re.search(pattern, text)\n",
    "#             if match:\n",
    "#                 return match.group(0)\n",
    "#         return \"Institution not specified\"\n",
    "\n",
    "#     def _parse_education_dates(self, text: str) -> Dict[str, str]:\n",
    "#         \"\"\"Extract education dates.\"\"\"\n",
    "#         date_pattern = r'(\\b(?:19|20)\\d{2}\\b)'\n",
    "#         dates = re.findall(date_pattern, text)\n",
    "        \n",
    "#         return {\n",
    "#             \"start\": dates[0] if dates else \"Unknown\",\n",
    "#             \"end\": dates[-1] if dates else \"Present\"\n",
    "#         }\n",
    "\n",
    "#     def _extract_gpa(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract GPA/IPK information.\"\"\"\n",
    "#         gpa_patterns = [\n",
    "#             r\"GPA:?\\s*([0-4]\\.\\d{1,2})\",\n",
    "#             r\"IPK:?\\s*([0-4]\\.\\d{1,2})\",\n",
    "#             r\"Grade Point Average:?\\s*([0-4]\\.\\d{1,2})\",\n",
    "#             r\"CGPA:?\\s*([0-4]\\.\\d{1,2})\"\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in gpa_patterns:\n",
    "#             match = re.search(pattern, text, re.IGNORECASE)\n",
    "#             if match:\n",
    "#                 return match.group(1)\n",
    "#         return None\n",
    "\n",
    "#     def _extract_honors(self, text: str) -> List[str]:\n",
    "#         \"\"\"Extract academic honors and achievements.\"\"\"\n",
    "#         honors_keywords = [\n",
    "#             \"cum laude\", \"magna cum laude\", \"summa cum laude\",\n",
    "#             \"honors\", \"distinction\", \"dean's list\", \"scholarship\",\n",
    "#             \"award\", \"fellowship\"\n",
    "#         ]\n",
    "        \n",
    "#         honors = []\n",
    "#         for keyword in honors_keywords:\n",
    "#             if keyword in text.lower():\n",
    "#                 # Find the complete honor phrase\n",
    "#                 match = re.search(f\"[A-Za-z\\s]+{keyword}[A-Za-z\\s]+\", text, re.IGNORECASE)\n",
    "#                 if match:\n",
    "#                     honors.append(match.group(0).strip())\n",
    "#                 else:\n",
    "#                     honors.append(keyword.title())\n",
    "        \n",
    "#         return honors\n",
    "\n",
    "#     def _extract_major(self, text: str) -> Optional[str]:\n",
    "#         \"\"\"Extract major/field of study.\"\"\"\n",
    "#         major_patterns = [\n",
    "#             r\"(?:in|of)\\s+([A-Z][A-Za-z\\s]+(?:Engineering|Science|Arts|Studies|Administration))\",\n",
    "#             r\"Major:?\\s*([A-Z][A-Za-z\\s]+)\",\n",
    "#             r\"Field of Study:?\\s*([A-Z][A-Za-z\\s]+)\"\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in major_patterns:\n",
    "#             match = re.search(pattern, text)\n",
    "#             if match:\n",
    "#                 return match.group(1)\n",
    "#         return None\n",
    "\n",
    "#     def extract_skills(self, text: str) -> Dict[str, List[str]]:\n",
    "#         \"\"\"Extract and categorize skills comprehensively.\"\"\"\n",
    "#         skills_section = self._find_skills_section(text)\n",
    "        \n",
    "#         # Extract skills using different methods\n",
    "#         found_skills = {\n",
    "#             \"technical\": self._extract_technical_skills(skills_section),\n",
    "#             \"soft\": self._extract_soft_skills(skills_section),\n",
    "#             \"languages\": self._extract_language_skills(skills_section),\n",
    "#             \"tools\": self._extract_tool_skills(skills_section),\n",
    "#             \"frameworks\": self._extract_framework_skills(skills_section),\n",
    "#             \"methodologies\": self._extract_methodology_skills(skills_section)\n",
    "#         }\n",
    "        \n",
    "#         # Add skills found in experience sections\n",
    "#         experience_skills = self._extract_skills_from_experience(text)\n",
    "#         for category in found_skills:\n",
    "#             found_skills[category].extend(skill for skill in experience_skills.get(category, [])\n",
    "#                                        if skill not in found_skills[category])\n",
    "        \n",
    "#         return found_skills\n",
    "\n",
    "#     def _find_skills_section(self, text: str) -> str:\n",
    "#         \"\"\"Locate the skills section in the text.\"\"\"\n",
    "#         skills_headers = [\n",
    "#             r\"SKILLS\",\n",
    "#             r\"TECHNICAL SKILLS\",\n",
    "#             r\"PROFESSIONAL SKILLS\",\n",
    "#             r\"COMPETENCIES\",\n",
    "#             r\"QUALIFICATIONS\"\n",
    "#         ]\n",
    "        \n",
    "#         sections = []\n",
    "#         lines = text.split('\\n')\n",
    "#         collecting = False\n",
    "#         current_section = []\n",
    "        \n",
    "#         for line in lines:\n",
    "#             if any(re.search(header, line, re.IGNORECASE) for header in skills_headers):\n",
    "#                 collecting = True\n",
    "#                 continue\n",
    "#             elif collecting and line.strip():\n",
    "#                 if any(header in line.upper() for header in [\"EXPERIENCE\", \"EDUCATION\", \"CERTIFICATIONS\"]):\n",
    "#                     break\n",
    "#                 current_section.append(line)\n",
    "                \n",
    "#         return ' '.join(current_section)\n",
    "\n",
    "#     def _extract_technical_skills(self, text: str) -> List[str]:\n",
    "#         \"\"\"Extract technical skills.\"\"\"\n",
    "#         skills = []\n",
    "        \n",
    "#         # Check against predefined technical skills\n",
    "#         for skill in self.technical_skills:\n",
    "#             if re.search(r'\\b' + re.escape(skill) + r'\\b', text.lower()):\n",
    "#                 skills.append(skill)\n",
    "        \n",
    "#         # Look for additional technical patterns\n",
    "#         tech_patterns = [\n",
    "#             r'\\b[A-Z][A-Za-z0-9#+]+\\b',  # Programming languages and technologies\n",
    "#             r'\\b[A-Za-z]+\\+\\+\\b',  # C++, etc.\n",
    "#             r'\\b[A-Za-z]+\\.js\\b',  # JavaScript frameworks\n",
    "#             r'\\b[A-Za-z]+SQL\\b'  # SQL variants\n",
    "#         ]\n",
    "        \n",
    "#         for pattern in tech_patterns:\n",
    "#             matches = re.findall(pattern, text)\n",
    "#             skills.extend(match.lower() for match in matches if match.lower() not in skills)\n",
    "        \n",
    "#         return sorted(list(set(skills)))\n",
    "\n",
    "#     def extract_certifications(self, text: str) -> List[Dict[str, str]]:\n",
    "#         \"\"\"Extract professional certifications and credentials.\"\"\"\n",
    "#         cert_sections = self._find_certification_sections(text)\n",
    "#         certifications = []\n",
    "        \n",
    "#         for section in cert_sections:\n",
    "#             certs = self._parse_certification_entries(section)\n",
    "#             certifications.extend(certs)\n",
    "            \n",
    "#         return certifications\n",
    "\n",
    "#     def _find_certification_sections(self, text: str) -> List[str]:\n",
    "#         \"\"\"Identify certification sections in the text.\"\"\"\n",
    "#         cert_headers = [\n",
    "#             r\"CERTIFICATIONS\",\n",
    "#             r\"CERTIFICATES\",\n",
    "#             r\"PROFESSIONAL CERTIFICATIONS\",\n",
    "#             r\"CREDENTIALS\",\n",
    "#             r\"LICENSES\"\n",
    "#         ]\n",
    "        \n",
    "#         sections = []\n",
    "#         lines = text.split('\\n')\n",
    "#         collecting = False\n",
    "#         current_section = []\n",
    "        \n",
    "#         for line in lines:\n",
    "#             if any(re.search(header, line, re.IGNORECASE) for header in cert_headers):\n",
    "#                 if collecting:\n",
    "#                     sections.append('\\n'.join(current_section))\n",
    "#                 collecting = True\n",
    "#                 current_section = []\n",
    "#             elif collecting and line.strip():\n",
    "#                 if any(header in line.upper() for header in [\"EXPERIENCE\", \"EDUCATION\", \"SKILLS\"]):\n",
    "#                     collecting = False\n",
    "#                     sections.append('\\n'.join(current_section))\n",
    "#                 else:\n",
    "#                     current_section.append(line)\n",
    "                    \n",
    "#         if collecting and current_section:\n",
    "#             sections.append('\\n'.join(current_section))\n",
    "            \n",
    "#         return sections\n",
    "\n",
    "#     def _parse_certification_entries(self, section: str) -> List[Dict[str, str]]:\n",
    "#         \"\"\"Parse individual certification entries.\"\"\"\n",
    "#         certifications = []\n",
    "#         lines = section.split('\\n')\n",
    "        \n",
    "#         for line in lines:\n",
    "#             if any(re.search(pattern, line, re.IGNORECASE) for pattern in self.certification_patterns):\n",
    "#                 cert_info = {\n",
    "#                     \"name\": self._extract_certification_name(line),\n",
    "#                     \"issuer\": self._extract_certification_issuer(line),\n",
    "#                     \"date\": self._extract_certification_date(line),\n",
    "#                     \"id\": self._extract_certification_id(line)\n",
    "#                 }\n",
    "#                 certifications.append(cert_info)\n",
    "                \n",
    "#         return certifications\n",
    "\n",
    "#     def extract_projects(self, text: str) -> List[Dict[str, str]]:\n",
    "#         \"\"\"Extract information about projects from the resume.\"\"\"\n",
    "#         project_sections = self._find_project_sections(text)\n",
    "#         projects = []\n",
    "        \n",
    "#         for section in project_sections:\n",
    "#             project_entries = self._parse_project_entries(section)\n",
    "#             projects.extend(project_entries)\n",
    "            \n",
    "#         return projects\n",
    "\n",
    "#     def export_to_json(self, parsed_data: Dict, output_path: str):\n",
    "#         \"\"\"Export parsed resume data to JSON format.\"\"\"\n",
    "#         try:\n",
    "#             with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#                 json.dump(parsed_data, f, indent=2)\n",
    "#         except Exception as e:\n",
    "#             raise Exception(f\"Error exporting to JSON: {str(e)}\")\n",
    "\n",
    "#     def export_to_csv(self, parsed_data: Dict, output_path: str):\n",
    "#         \"\"\"Export parsed resume data to CSV format.\"\"\"\n",
    "#         try:\n",
    "#             # Flatten the dictionary for CSV export\n",
    "#             flattened_data = self._flatten_dict(parsed_data)\n",
    "            \n",
    "#             with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "#                 writer = csv.DictWriter(f, fieldnames=flattened_data.keys())\n",
    "#                 writer.writeheader()\n",
    "#                 writer.writerow(flattened_data)\n",
    "#         except Exception as e:\n",
    "#             raise Exception(f\"Error exporting to CSV: {str(e)}\")\n",
    "\n",
    "#     def _flatten_dict(self, d: Dict, parent_key: str = '', sep: str = '_') -> Dict:\n",
    "#         \"\"\"Flatten a nested dictionary for CSV export.\"\"\"\n",
    "#         items = []\n",
    "#         for k, v in d.items():\n",
    "#             new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "#             if isinstance(v, dict):\n",
    "#                 items.extend(self._flatten_dict(v, new_key, sep).items())\n",
    "#             elif isinstance(v, list):\n",
    "#                 items.append((new_key, '; '.join(str(item) for item in v)))\n",
    "#             else:\n",
    "#                 items.append((new_key, v))\n",
    "#         return dict(items)\n",
    "\n",
    "#     def parse_resume(self, file_path: str, file_type: str = \"pdf\") -> Dict:\n",
    "#         \"\"\"Main function to parse resume and extract all information.\"\"\"\n",
    "#         try:\n",
    "#             # Extract text based on file type\n",
    "#             text = self.extract_text_from_pdf(file_path) if file_type == \"pdf\" else self.extract_text_from_docx(file_path)\n",
    "            \n",
    "#             # Parse all components\n",
    "#             parsed_data = {\n",
    "#                 \"contact_info\": self.extract_contact_info(text),\n",
    "#                 \"experience\": self.extract_experience(text),\n",
    "#                 \"education\": self.extract_education(text),\n",
    "#                 \"skills\": self.extract_skills(text),\n",
    "#                 \"certifications\": self.extract_certifications(text),\n",
    "#                 \"projects\": self.extract_projects(text),\n",
    "#                 \"parsing_success\": self.calculate_parsing_success(text)\n",
    "#             }\n",
    "            \n",
    "#             return parsed_data\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             raise Exception(f\"Error parsing resume: {str(e)}\")\n",
    "\n",
    "#     def calculate_parsing_success(self, text: str) -> Dict[str, float]:\n",
    "#         \"\"\"Calculate parsing success rates for different components.\"\"\"\n",
    "#         success_metrics = {\n",
    "#             \"contact_info\": self._calculate_contact_info_success(text),\n",
    "#             \"experience\": self._calculate_experience_success(text),\n",
    "#             \"education\": self._calculate_education_success(text),\n",
    "#             \"skills\": self._calculate_skills_success(text),\n",
    "#             \"overall\": 0.0\n",
    "#         }\n",
    "        \n",
    "#         # Calculate overall success rate\n",
    "#         success_metrics[\"overall\"] = sum(success_metrics.values()) / len(success_metrics)\n",
    "        \n",
    "#         return success_metrics\n",
    "\n",
    "# # Function untuk mengunggah file dan menampilkan hasil parsing\n",
    "# def on_file_upload(change):\n",
    "#     try:\n",
    "#         # Mendapatkan file yang diunggah\n",
    "#         file_upload = change['owner']\n",
    "        \n",
    "#         if not file_upload.value:  # Check if any file was uploaded\n",
    "#             print(\"No file uploaded\")\n",
    "#             return\n",
    "            \n",
    "#         # Get the first uploaded file\n",
    "#         uploaded_file = file_upload.value[0]  # Access first element of the tuple\n",
    "        \n",
    "#         # Nama file dan konten\n",
    "#         file_name = uploaded_file.name\n",
    "#         file_content = uploaded_file.content\n",
    "#         file_path = f\"./{file_name}\"\n",
    "        \n",
    "#         # Menyimpan file yang diunggah\n",
    "#         with open(file_path, \"wb\") as f:\n",
    "#             f.write(file_content)\n",
    "        \n",
    "#         # Tentukan tipe file (pdf atau docx)\n",
    "#         file_type = \"pdf\" if file_name.lower().endswith(\".pdf\") else \"docx\"\n",
    "        \n",
    "#         # Initialize parser and parse resume\n",
    "#         parser = ResumeParser()\n",
    "#         parsed_data = parser.parse_resume(file_path, file_type)\n",
    "        \n",
    "#         # Export results\n",
    "#         timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#         base_name = os.path.splitext(file_name)[0]\n",
    "        \n",
    "#         # Export to JSON\n",
    "#         json_path = f\"{base_name}_{timestamp}_parsed.json\"\n",
    "#         parser.export_to_json(parsed_data, json_path)\n",
    "        \n",
    "#         # Export to CSV\n",
    "#         csv_path = f\"{base_name}_{timestamp}_parsed.csv\"\n",
    "#         parser.export_to_csv(parsed_data, csv_path)\n",
    "        \n",
    "#         # Display results\n",
    "#         print(\"\\nParsed Resume Data:\")\n",
    "#         print(json.dumps(parsed_data, indent=2))\n",
    "#         print(f\"\\nResults exported to {json_path} and {csv_path}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing file: {str(e)}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# # Create upload widget\n",
    "# file_upload_widget = FileUpload(\n",
    "#     accept='.pdf, .docx',\n",
    "#     multiple=False,\n",
    "#     description='Upload Resume'\n",
    "# )\n",
    "# file_upload_widget.observe(on_file_upload, names='value')\n",
    "# display(file_upload_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb95625d8a841339d514185ce36a15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf, .docx', description='üìé Upload Resume')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processing file: CV_Faizal Lutfi Yoga Triadi.pdf\n",
      "\n",
      "üìÑ RESUME PARSING RESULTS üìÑ\n",
      "==================================================\n",
      "üìû Contact Information:\n",
      "------------------------------\n",
      "üë§ Name: linkedin.com/in/faizallutfiyt |\n",
      "üìß Email: faizal2jz@gmail.com\n",
      "üì± Phone: 6281215758979\n",
      "üìç Location: Python, Jakarta, Indonesia\n",
      "üíº LinkedIn: https://www.linkedin.com/in/faizallutfiyt\n",
      "üíª GitHub: https://www.github.com/abcdullahh\n",
      "\n",
      "üîß Skills:\n",
      "------------------------------\n",
      "\n",
      "üíª Technical:\n",
      "JavaScript, Python\n",
      "\n",
      "==================================================\n",
      "                   ACHIEVEMENTS                   \n",
      "==================================================\n",
      "üèÜ recognized for strong analytical skills and dedication to learning\n",
      "\n",
      "üìä ATS COMPATIBILITY SCORING üìä\n",
      "==================================================\n",
      "\n",
      "üéØ Overall ATS Compatibility Score: 17.81%\n",
      "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí]\n",
      "\n",
      "üìà Detailed Scores:\n",
      "--------------------------------------------------\n",
      "üë§ Contact Information: 93.75% [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñí‚ñí]\n",
      "üíº Work Experience: 0.0% [‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí]\n",
      "üéì Education: 0.0% [‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí]\n",
      "üîß Skills: 10.0% [‚ñà‚ñà‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí]\n",
      "üöÄ Projects: 0.0% [‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí]\n",
      "üìú Certifications: 0.0% [‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí]\n",
      "üìã Formatting: 35.0% [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí‚ñí]\n",
      "\n",
      "üéØ Score Interpretation:\n",
      "--------------------------------------------------\n",
      "Overall: Needs improvement for ATS compatibility\n",
      "\n",
      "üí™ Strengths:\n",
      "‚úì Contact\n",
      "\n",
      "üîç Areas for Improvement:\n",
      "‚Ä¢ Experience\n",
      "‚Ä¢ Education\n",
      "‚Ä¢ Skills\n",
      "‚Ä¢ Projects\n",
      "‚Ä¢ Certifications\n",
      "‚Ä¢ Formatting\n",
      "\n",
      "üí° Improvement Suggestions:\n",
      "--------------------------------------------------\n",
      "‚ñ∫ Include more detailed work responsibilities and achievements\n",
      "‚ñ∫ Add more relevant technical and soft skills with clear categorization\n",
      "‚ñ∫ Provide more details about educational background, including GPA and honors\n",
      "‚ñ∫ Improve overall resume structure and organization\n",
      "\n",
      "‚úÖ Results exported to:\n",
      "üìÑ JSON: CV_Faizal Lutfi Yoga Triadi_20241105_053633_parsed.json\n",
      "üìÑ CSV: CV_Faizal Lutfi Yoga Triadi_20241105_053633_parsed.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from docx import Document\n",
    "import re\n",
    "import spacy\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from typing import Dict, List, Optional, Tuple, Any, Union\n",
    "import csv\n",
    "from dateutil.parser import parse\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class ResumeParser:\n",
    "    def __init__(self):\n",
    "        self.skill_context_markers = {\n",
    "            \"technical\": [\n",
    "                \"programming languages\", \"tech stack\", \"technical skills\",\n",
    "                \"development tools\", \"technologies used\", \"software\",\n",
    "                \"proficient in\", \"expertise in\", \"experienced with\",\n",
    "                \"programming\", \"coding\", \"development\", \"engineering\",\n",
    "                \"backend\", \"frontend\", \"full stack\", \"technical\"\n",
    "            ],\n",
    "            \"frameworks\": [\n",
    "                \"frameworks\", \"libraries\", \"platforms\", \"development frameworks\",\n",
    "                \"web frameworks\", \"mobile frameworks\", \"api frameworks\",\n",
    "                \"using\", \"built with\", \"developed with\", \"implemented using\"\n",
    "            ],\n",
    "            \"tools\": [\n",
    "                \"tools\", \"development tools\", \"software tools\", \"ide\", \"editors\",\n",
    "                \"version control\", \"build tools\", \"deployment tools\",\n",
    "                \"environment\", \"workspace\", \"utilities\", \"applications\"\n",
    "            ],\n",
    "            \"databases\": [\n",
    "                \"databases\", \"data stores\", \"storage\", \"sql\", \"nosql\",\n",
    "                \"database management\", \"data warehousing\", \"data storage\",\n",
    "                \"persistence\", \"data layer\", \"database systems\"\n",
    "            ],\n",
    "            \"methodologies\": [\n",
    "                \"methodologies\", \"practices\", \"processes\", \"approaches\",\n",
    "                \"development methodologies\", \"project management\",\n",
    "                \"workflow\", \"standards\", \"principles\", \"patterns\"\n",
    "            ],\n",
    "            \"soft_skills\": [\n",
    "                \"soft skills\", \"interpersonal skills\", \"communication\",\n",
    "                \"leadership\", \"management\", \"collaboration\", \"teamwork\",\n",
    "                \"problem solving\", \"analytical\", \"organizational\"\n",
    "            ],\n",
    "            \"languages\": [\n",
    "                \"programming languages\", \"spoken languages\", \"written languages\",\n",
    "                \"fluent in\", \"native\", \"bilingual\", \"multilingual\",\n",
    "                \"language proficiency\", \"foreign languages\"\n",
    "            ],\n",
    "            \"cloud\": [\n",
    "                \"cloud platforms\", \"cloud services\", \"cloud computing\",\n",
    "                \"cloud infrastructure\", \"cloud architecture\", \"saas\",\n",
    "                \"paas\", \"iaas\", \"cloud native\", \"containerization\"\n",
    "            ],\n",
    "            \"data_science\": [\n",
    "                \"machine learning\", \"data analysis\", \"statistics\", \n",
    "                \"data visualization\", \"big data\", \"data mining\",\n",
    "                \"predictive modeling\", \"data science\", \"analytics\"\n",
    "            ],\n",
    "            \"security\": [\n",
    "                \"security\", \"cybersecurity\", \"information security\",\n",
    "                \"network security\", \"application security\", \"devsecops\",\n",
    "                \"security practices\", \"security tools\", \"cryptography\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        \n",
    "        self.experience_markers = {\n",
    "        \"titles\": {\n",
    "            \"senior\": [\n",
    "                \"senior\", \"sr.\", \"lead\", \"principal\", \"staff\", \"chief\", \"head\",\n",
    "                \"distinguished\", \"expert\", \"architect\", \"director\", \"manager\",\n",
    "                \"tech lead\", \"team lead\", \"group lead\", \"technical lead\",\n",
    "                \"solution architect\", \"enterprise architect\", \"senior staff\"\n",
    "            ],\n",
    "            \"mid_level\": [\n",
    "                \"intermediate\", \"mid-level\", \"associate\", \"regular\", \"II\", \"III\",\n",
    "                \"specialist\", \"experienced\", \"professional\", \"advanced\"\n",
    "            ],\n",
    "            \"junior\": [\n",
    "                \"junior\", \"jr.\", \"entry level\", \"entry-level\", \"trainee\",\n",
    "                \"graduate\", \"associate\", \"apprentice\", \"I\"\n",
    "            ],\n",
    "            \"roles\": [\n",
    "                # Engineering Roles\n",
    "                \"engineer\", \"developer\", \"programmer\", \"architect\", \"administrator\",\n",
    "                \"technician\", \"specialist\", \"analyst\", \"consultant\", \"designer\",\n",
    "                \"researcher\", \"scientist\", \"technologist\", \"evangelist\",\n",
    "\n",
    "                # Management Roles\n",
    "                \"manager\", \"director\", \"supervisor\", \"coordinator\", \"team leader\",\n",
    "                \"project manager\", \"product manager\", \"program manager\", \"head\",\n",
    "                \"chief\", \"vp\", \"vice president\", \"executive\", \"lead\",\n",
    "\n",
    "                # Specialized Technical Roles\n",
    "                \"devops\", \"sre\", \"reliability engineer\", \"security engineer\",\n",
    "                \"data scientist\", \"machine learning engineer\", \"ai engineer\",\n",
    "                \"cloud architect\", \"solutions architect\", \"database administrator\",\n",
    "                \"full stack developer\", \"frontend developer\", \"backend developer\",\n",
    "                \"mobile developer\", \"qa engineer\", \"test engineer\", \"system analyst\",\n",
    "\n",
    "                # Consulting/Advisory Roles\n",
    "                \"consultant\", \"advisor\", \"strategist\", \"specialist\", \"expert\",\n",
    "                \"trainer\", \"mentor\", \"coach\", \"advocate\"\n",
    "            ],\n",
    "            \"domains\": [\n",
    "                # Software Development\n",
    "                \"software\", \"application\", \"systems\", \"web\", \"mobile\", \"cloud\",\n",
    "                \"enterprise\", \"platform\", \"solution\", \"product\", \"full stack\",\n",
    "                \"full-stack\", \"frontend\", \"front-end\", \"backend\", \"back-end\",\n",
    "\n",
    "                # Data & Analytics\n",
    "                \"data\", \"analytics\", \"business intelligence\", \"machine learning\",\n",
    "                \"artificial intelligence\", \"ai\", \"ml\", \"deep learning\", \"nlp\",\n",
    "                \"big data\", \"data science\", \"statistics\",\n",
    "\n",
    "                # Infrastructure & Operations\n",
    "                \"infrastructure\", \"network\", \"system\", \"cloud\", \"devops\",\n",
    "                \"site reliability\", \"platform\", \"security\", \"cybersecurity\",\n",
    "                \"information security\", \"cloud native\", \"multicloud\",\n",
    "\n",
    "                # Specialized Areas\n",
    "                \"embedded\", \"iot\", \"blockchain\", \"ar/vr\", \"gaming\", \"quantum\",\n",
    "                \"robotics\", \"automation\", \"high performance computing\",\n",
    "                \"distributed systems\", \"microservices\", \"serverless\",\n",
    "\n",
    "                # Business Domains\n",
    "                \"financial\", \"healthcare\", \"e-commerce\", \"retail\", \"banking\",\n",
    "                \"insurance\", \"telecommunications\", \"media\", \"entertainment\",\n",
    "                \"education\", \"government\", \"manufacturing\", \"logistics\"\n",
    "            ]\n",
    "        },\n",
    "        \"action_verbs\": {\n",
    "            \"leadership\": [\n",
    "                \"led\", \"managed\", \"directed\", \"supervised\", \"oversaw\", \"guided\",\n",
    "                \"mentored\", \"coached\", \"trained\", \"coordinated\", \"spearheaded\",\n",
    "                \"championed\", \"orchestrated\", \"initiated\", \"pioneered\", \"founded\",\n",
    "                \"established\", \"launched\", \"headed\", \"chaired\"\n",
    "            ],\n",
    "            \"development\": [\n",
    "                \"developed\", \"created\", \"built\", \"designed\", \"architected\",\n",
    "                \"implemented\", \"programmed\", \"coded\", \"engineered\", \"constructed\",\n",
    "                \"devised\", \"formulated\", \"authored\", \"prototyped\", \"crafted\",\n",
    "                \"customized\", \"maintained\", \"enhanced\", \"upgraded\", \"modernized\"\n",
    "            ],\n",
    "            \"improvement\": [\n",
    "                \"improved\", \"optimized\", \"enhanced\", \"streamlined\", \"accelerated\",\n",
    "                \"automated\", \"simplified\", \"modernized\", \"transformed\", \"revamped\",\n",
    "                \"refactored\", \"redesigned\", \"restructured\", \"reengineered\",\n",
    "                \"standardized\", \"unified\", \"consolidated\", \"integrated\"\n",
    "            ],\n",
    "            \"achievement\": [\n",
    "                \"achieved\", \"delivered\", \"completed\", \"succeeded\", \"accomplished\",\n",
    "                \"attained\", \"earned\", \"won\", \"secured\", \"generated\", \"produced\",\n",
    "                \"increased\", \"decreased\", \"reduced\", \"saved\", \"eliminated\",\n",
    "                \"exceeded\", \"outperformed\", \"surpassed\"\n",
    "            ],\n",
    "            \"analysis\": [\n",
    "                \"analyzed\", \"evaluated\", \"assessed\", \"researched\", \"investigated\",\n",
    "                \"studied\", \"examined\", \"reviewed\", \"monitored\", \"tracked\",\n",
    "                \"measured\", \"quantified\", \"diagnosed\", \"identified\", \"discovered\",\n",
    "                \"uncovered\", \"determined\", \"validated\", \"verified\"\n",
    "            ],\n",
    "            \"collaboration\": [\n",
    "                \"collaborated\", \"partnered\", \"cooperated\", \"worked\", \"liaised\",\n",
    "                \"coordinated\", \"facilitated\", \"negotiated\", \"mediated\",\n",
    "                \"communicated\", \"consulted\", \"advised\", \"counseled\", \"guided\",\n",
    "                \"interfaced\", \"engaged\", \"participated\", \"contributed\"\n",
    "            ]\n",
    "        },\n",
    "        \"metrics\": {\n",
    "            \"performance\": [\n",
    "                r\"\\d+%\", r\"\\d+\\s*percent\",\n",
    "                r\"(?:increased|decreased|reduced|improved|grew|enhanced|saved)\\s+by\\s+\\d+%\",\n",
    "                r\"(?:increased|decreased|reduced|improved|grew|enhanced|saved)\\s+\\d+%\",\n",
    "                r\"\\d+x\\s*(?:improvement|increase|faster|better|growth)\",\n",
    "                r\"factor\\s+of\\s+\\d+\"\n",
    "            ],\n",
    "            \"financial\": [\n",
    "                r\"\\$\\d+(?:K|k|M|m|B|b)?(?:\\+)?\",\n",
    "                r\"\\d+\\s*(?:thousand|million|billion|K|k|M|m|B|b)\",\n",
    "                r\"(?:USD|EUR|GBP)\\s*\\d+(?:K|k|M|m|B|b)?\",\n",
    "                r\"savings of \\$\\d+(?:K|k|M|m|B|b)?\",\n",
    "                r\"revenue of \\$\\d+(?:K|k|M|m|B|b)?\"\n",
    "            ],\n",
    "            \"scale\": [\n",
    "                r\"\\d+\\+?\\s*(?:users|clients|customers|employees|team members)\",\n",
    "                r\"team of \\d+\\+?(?:\\s*(?:-|to)\\s*\\d+)?\",\n",
    "                r\"\\d+\\+?\\s*(?:countries|locations|markets|regions)\",\n",
    "                r\"\\d+\\+?\\s*(?:projects|products|applications|systems)\",\n",
    "                r\"(?:global|worldwide|international)\\s+team of \\d+\"\n",
    "            ],\n",
    "            \"time\": [\n",
    "                r\"\\d+\\+?\\s*(?:hours|days|weeks|months|years)\",\n",
    "                r\"reduced time by \\d+%\",\n",
    "                r\"within \\d+\\s*(?:days|weeks|months)\",\n",
    "                r\"under \\d+\\s*(?:days|weeks|months)\",\n",
    "                r\"(?:daily|weekly|monthly|annual|yearly)\\s+savings of \\d+\"\n",
    "            ],\n",
    "            \"technical\": [\n",
    "                r\"\\d+\\+?\\s*(?:APIs|microservices|endpoints|servers|databases)\",\n",
    "                r\"\\d+\\+?\\s*(?:tests|commits|deployments|releases)\",\n",
    "                r\"\\d+\\+?\\s*(?:GB|TB|PB|transactions|requests|events)/(?:day|month|year)\",\n",
    "                r\"(?:decreased|reduced|improved)\\s+(?:latency|load time|response time)\\s+by\\s+\\d+%\",\n",
    "                r\"\\d+\\s*(?:nines|%)\\s*availability\",\n",
    "                r\"\\d+\\+?\\s*(?:repositories|services|containers|instances)\"\n",
    "            ]\n",
    "        },\n",
    "        \"impacts\": {\n",
    "            \"business\": [\n",
    "                \"cost savings\", \"revenue growth\", \"profit increase\",\n",
    "                \"market share\", \"customer satisfaction\", \"user adoption\",\n",
    "                \"business expansion\", \"new markets\", \"competitive advantage\",\n",
    "                \"operational efficiency\", \"productivity gains\", \"roi\"\n",
    "            ],\n",
    "            \"technical\": [\n",
    "                \"system performance\", \"scalability\", \"reliability\",\n",
    "                \"code quality\", \"test coverage\", \"deployment frequency\",\n",
    "                \"incident reduction\", \"security posture\", \"technical debt\",\n",
    "                \"maintainability\", \"availability\", \"response time\"\n",
    "            ],\n",
    "            \"organizational\": [\n",
    "                \"team productivity\", \"process improvement\", \"workflow optimization\",\n",
    "                \"knowledge sharing\", \"best practices\", \"standards compliance\",\n",
    "                \"cross-functional collaboration\", \"stakeholder management\",\n",
    "                \"resource utilization\", \"training effectiveness\"\n",
    "            ]\n",
    "        },\n",
    "        \"technologies\": {\n",
    "            \"programming_languages\": {\n",
    "                \"primary\": [\n",
    "                    \"java\", \"python\", \"javascript\", \"typescript\", \"c++\", \"c#\",\n",
    "                    \"go\", \"rust\", \"ruby\", \"php\", \"swift\", \"kotlin\"\n",
    "                ],\n",
    "                \"secondary\": [\n",
    "                    \"scala\", \"perl\", \"r\", \"matlab\", \"shell\", \"bash\", \"powershell\",\n",
    "                    \"groovy\", \"lua\", \"dart\", \"haskell\", \"erlang\", \"elixir\"\n",
    "                ]\n",
    "            },\n",
    "            \"frameworks\": {\n",
    "                \"web\": [\n",
    "                    \"react\", \"angular\", \"vue\", \"django\", \"spring\", \"flask\",\n",
    "                    \"express\", \"nextjs\", \"nuxt\", \"svelte\", \"laravel\", \"rails\"\n",
    "                ],\n",
    "                \"mobile\": [\n",
    "                    \"react native\", \"flutter\", \"ionic\", \"xamarin\", \"android sdk\",\n",
    "                    \"ios sdk\", \"swiftui\", \"jetpack compose\", \"kotlin multiplatform\"\n",
    "                ],\n",
    "                \"data\": [\n",
    "                    \"tensorflow\", \"pytorch\", \"keras\", \"scikit-learn\", \"pandas\",\n",
    "                    \"spark\", \"hadoop\", \"numpy\", \"scipy\", \"matplotlib\"\n",
    "                ]\n",
    "            },\n",
    "            \"cloud\": {\n",
    "                \"platforms\": [\n",
    "                    \"aws\", \"azure\", \"gcp\", \"alibaba cloud\", \"oracle cloud\",\n",
    "                    \"ibm cloud\", \"digitalocean\", \"heroku\", \"openshift\"\n",
    "                ],\n",
    "                \"services\": [\n",
    "                    \"ec2\", \"s3\", \"lambda\", \"eks\", \"rds\", \"dynamodb\",\n",
    "                    \"azure functions\", \"app service\", \"cloud run\", \"bigquery\"\n",
    "                ]\n",
    "            },\n",
    "            \"databases\": {\n",
    "                \"sql\": [\n",
    "                    \"mysql\", \"postgresql\", \"sql server\", \"oracle\", \"sqlite\",\n",
    "                    \"mariadb\", \"aurora\", \"cockroachdb\"\n",
    "                ],\n",
    "                \"nosql\": [\n",
    "                    \"mongodb\", \"cassandra\", \"redis\", \"elasticsearch\", \"dynamodb\",\n",
    "                    \"neo4j\", \"couchbase\", \"firebase\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "        \n",
    "        # Initialize skill databases\n",
    "        self.technical_skills = {\n",
    "            \"programming_languages\": {\n",
    "                \"python\", \"java\", \"javascript\", \"c++\", \"c#\", \"ruby\", \"php\",\n",
    "                \"swift\", \"kotlin\", \"go\", \"rust\", \"typescript\", \"scala\"\n",
    "            },\n",
    "            \"web_technologies\": {\n",
    "                \"html\", \"css\", \"react\", \"angular\", \"vue\", \"node.js\", \"express\",\n",
    "                \"django\", \"flask\", \"spring\", \"asp.net\"\n",
    "            },\n",
    "            \"databases\": {\n",
    "                \"sql\", \"mysql\", \"postgresql\", \"mongodb\", \"redis\", \"oracle\",\n",
    "                \"cassandra\", \"elasticsearch\"\n",
    "            },\n",
    "            \"cloud_platforms\": {\n",
    "                \"aws\", \"azure\", \"gcp\", \"docker\", \"kubernetes\", \"terraform\",\n",
    "                \"jenkins\", \"circleci\", \"github actions\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.soft_skills = {\n",
    "            \"leadership\": {\n",
    "                \"team leadership\", \"mentoring\", \"strategic planning\",\n",
    "                \"decision making\", \"delegation\", \"conflict resolution\"\n",
    "            },\n",
    "            \"communication\": {\n",
    "                \"verbal communication\", \"written communication\", \"presentation\",\n",
    "                \"public speaking\", \"negotiation\", \"interpersonal skills\"\n",
    "            },\n",
    "            \"management\": {\n",
    "                \"project management\", \"time management\", \"risk management\",\n",
    "                \"change management\", \"resource management\", \"agile\", \"scrum\"\n",
    "            },\n",
    "            \"personal\": {\n",
    "                \"problem solving\", \"analytical\", \"critical thinking\",\n",
    "                \"creativity\", \"adaptability\", \"attention to detail\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.tools = {\n",
    "            \"development\": {\n",
    "                \"git\", \"vscode\", \"intellij\", \"eclipse\", \"sublime\",\n",
    "                \"postman\", \"docker\", \"kubernetes\", \"jenkins\"\n",
    "            },\n",
    "            \"design\": {\n",
    "                \"photoshop\", \"illustrator\", \"figma\", \"sketch\",\n",
    "                \"adobe xd\", \"indesign\"\n",
    "            },\n",
    "            \"productivity\": {\n",
    "                \"jira\", \"confluence\", \"trello\", \"asana\", \"slack\",\n",
    "                \"microsoft office\", \"google workspace\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _extract_portfolio(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract portfolio website URL.\"\"\"\n",
    "        portfolio_patterns = [\n",
    "            r'portfolio:?\\s*(https?://[^\\s]+)',\n",
    "            r'website:?\\s*(https?://[^\\s]+)',\n",
    "            r'blog:?\\s*(https?://[^\\s]+)',\n",
    "            r'(https?://(?:www\\.)?[^\\s]+\\.(?:com|io|dev|me)(?:/[^\\s]*)?)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in portfolio_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        return None\n",
    "\n",
    "    def _extract_summary(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract professional summary or objective.\"\"\"\n",
    "        summary_headers = [\n",
    "            \"SUMMARY\", \"PROFESSIONAL SUMMARY\", \"CAREER OBJECTIVE\",\n",
    "            \"OBJECTIVE\", \"PROFILE\", \"ABOUT\"\n",
    "        ]\n",
    "        \n",
    "        # Find the summary section\n",
    "        summary_section = self._find_section(text, summary_headers)\n",
    "        if summary_section:\n",
    "            # Clean and return the first paragraph\n",
    "            sentences = sent_tokenize(summary_section)\n",
    "            if sentences:\n",
    "                return ' '.join(sentences[:3])  # Return first 3 sentences\n",
    "        return None\n",
    "\n",
    "    def _find_section_content(self, text: str, headers: List[str]) -> Optional[str]:\n",
    "        \"\"\"Find section and extract all content below it until next section.\"\"\"\n",
    "        # Normalize text\n",
    "        lines = text.split('\\n')\n",
    "        section_content = []\n",
    "        in_section = False\n",
    "        \n",
    "        # Common section headers for detecting next section\n",
    "        common_headers = {\n",
    "            \"EXPERIENCE\", \"WORK EXPERIENCE\", \"EMPLOYMENT\",\n",
    "            \"EDUCATION\", \"ACADEMIC BACKGROUND\", \"QUALIFICATIONS\",\n",
    "            \"SKILLS\", \"TECHNICAL SKILLS\", \"COMPETENCIES\", \"EXPERTISE\",\n",
    "            \"PROJECTS\", \"PROJECT EXPERIENCE\", \"KEY PROJECTS\",\n",
    "            \"CERTIFICATIONS\", \"CERTIFICATES\", \"CREDENTIALS\",\n",
    "            \"SUMMARY\", \"OBJECTIVE\", \"PROFILE\",\n",
    "            \"ACTIVITIES\", \"ACHIEVEMENTS\", \"AWARDS\",\n",
    "            \"PUBLICATIONS\", \"RESEARCH\", \"INTERESTS\"\n",
    "        }\n",
    "\n",
    "        # Add variations of headers\n",
    "        header_variations = set()\n",
    "        for header in common_headers:\n",
    "            header_variations.add(header.lower())\n",
    "            header_variations.add(header.title())\n",
    "        common_headers.update(header_variations)\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Check if line is target section header\n",
    "            if any(header.lower() in line.lower() for header in headers):\n",
    "                in_section = True\n",
    "                continue\n",
    "\n",
    "            # Check if new section started\n",
    "            if in_section and line:\n",
    "                if any(header in line for header in common_headers):\n",
    "                    break\n",
    "                section_content.append(line)\n",
    "\n",
    "        return '\\n'.join(section_content) if section_content else None\n",
    "\n",
    "    def _extract_achievements(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract achievements and key accomplishments.\"\"\"\n",
    "        achievement_patterns = [\n",
    "            r'increased\\s+[\\w\\s]+\\s+by\\s+\\d+%',\n",
    "            r'reduced\\s+[\\w\\s]+\\s+by\\s+\\d+%',\n",
    "            r'improved\\s+[\\w\\s]+\\s+by\\s+\\d+%',\n",
    "            r'generated\\s+[\\w\\s]+\\s+\\$\\d+',\n",
    "            r'awarded\\s+[\\w\\s]+',\n",
    "            r'recognized\\s+[\\w\\s]+'\n",
    "        ]\n",
    "        \n",
    "        achievements = []\n",
    "        for pattern in achievement_patterns:\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                achievements.append(match.group(0))\n",
    "        return achievements\n",
    "\n",
    "    def _extract_certification_name(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract certification name.\"\"\"\n",
    "        cert_patterns = [\n",
    "            r\"(?:certification|certificate) in (.+?)(?:\\(|\\n|$)\",\n",
    "            r\"(\\w+ certified \\w+)\",\n",
    "            r\"((?:AWS|Azure|Google|Microsoft|Cisco|CompTIA|ITIL)[\\w\\s]+ certification)\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in cert_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        return None\n",
    "\n",
    "    def _extract_certification_issuer(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract certification issuer.\"\"\"\n",
    "        common_issuers = [\n",
    "            \"Amazon\", \"AWS\", \"Microsoft\", \"Google\", \"Oracle\", \"Cisco\",\n",
    "            \"CompTIA\", \"PMI\", \"ISACA\", \"(ISC)¬≤\", \"Red Hat\", \"IBM\"\n",
    "        ]\n",
    "        \n",
    "        for issuer in common_issuers:\n",
    "            if issuer.lower() in text.lower():\n",
    "                return issuer\n",
    "        return None\n",
    "\n",
    "    def _extract_certification_date(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract certification date.\"\"\"\n",
    "        date_pattern = r'(?:issued|completed|achieved|earned|received|obtained)\\s+(?:on|in)?\\s*((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4})'\n",
    "        match = re.search(date_pattern, text, re.IGNORECASE)\n",
    "        return match.group(1) if match else None\n",
    "\n",
    "    def _extract_certification_id(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract certification ID or credential ID.\"\"\"\n",
    "        id_patterns = [\n",
    "            r'credential id[:\\s]+([a-z0-9-]+)',\n",
    "            r'certification (?:id|number)[:\\s]+([a-z0-9-]+)',\n",
    "            r'certificate (?:id|number)[:\\s]+([a-z0-9-]+)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in id_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "        return None\n",
    "\n",
    "    def _extract_certification_validity(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract certification validity period.\"\"\"\n",
    "        valid_from_pattern = r'valid from[:\\s]+([\\w\\s]+\\d{4})'\n",
    "        valid_until_pattern = r'valid (?:until|through)[:\\s]+([\\w\\s]+\\d{4})'\n",
    "        \n",
    "        valid_from = re.search(valid_from_pattern, text, re.IGNORECASE)\n",
    "        valid_until = re.search(valid_until_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        return {\n",
    "            \"valid_from\": valid_from.group(1) if valid_from else None,\n",
    "            \"valid_until\": valid_until.group(1) if valid_until else None\n",
    "        }\n",
    "\n",
    "    def _extract_project_name(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract project name.\"\"\"\n",
    "        # Look for project name at the start of the text or after common headers\n",
    "        patterns = [\n",
    "            r'^([A-Z][^:]+?)(?::|‚Äì|-|\\n)',\n",
    "            r'project name[:\\s]+([^:]+?)(?:\\n|$)',\n",
    "            r'project title[:\\s]+([^:]+?)(?:\\n|$)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        return None\n",
    "\n",
    "    def _extract_project_description(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract project description.\"\"\"\n",
    "        # Look for description after common markers\n",
    "        patterns = [\n",
    "            r'description[:\\s]+(.+?)(?:\\n\\n|$)',\n",
    "            r'overview[:\\s]+(.+?)(?:\\n\\n|$)',\n",
    "            r'summary[:\\s]+(.+?)(?:\\n\\n|$)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        \n",
    "        # If no explicit description found, take the first substantial paragraph\n",
    "        paragraphs = text.split('\\n\\n')\n",
    "        for para in paragraphs:\n",
    "            if len(para.strip()) > 50:  # Minimum length for a description\n",
    "                return para.strip()\n",
    "        return None\n",
    "\n",
    "    def _extract_project_url(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract project URL.\"\"\"\n",
    "        url_patterns = [\n",
    "            r'(?:url|link|github|gitlab)[:\\s]+(https?://[^\\s]+)',\n",
    "            r'(https?://github\\.com/[^\\s]+)',\n",
    "            r'(https?://gitlab\\.com/[^\\s]+)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in url_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "        return None\n",
    "\n",
    "\n",
    "    def parse_resume(self, file_path: str, file_type: str = \"pdf\") -> Dict[str, Any]:\n",
    "        \"\"\"Parse resume and extract all information.\"\"\"\n",
    "        try:\n",
    "            # Extract text based on file type\n",
    "            text = self.extract_text_from_pdf(file_path) if file_type.lower() == \"pdf\" else self.extract_text_from_docx(file_path)\n",
    "            \n",
    "            # Extract all components\n",
    "            parsed_data = {\n",
    "                \"contact_info\": self.extract_contact_info(text),\n",
    "                \"summary\": self._extract_summary(text),\n",
    "                \"experience\": self.extract_experience(text) if hasattr(self, 'extract_experience') else [],\n",
    "                \"education\": self.extract_education(text) if hasattr(self, 'extract_education') else [],\n",
    "                \"skills\": self.extract_skills(text),\n",
    "                \"certifications\": self.extract_certifications(text) if hasattr(self, 'extract_certifications') else [],\n",
    "                \"projects\": self.extract_projects(text) if hasattr(self, 'extract_projects') else [],\n",
    "                \"achievements\": self._extract_achievements(text),\n",
    "                \"metadata\": {\n",
    "                    \"file_name\": os.path.basename(file_path),\n",
    "                    \"file_type\": file_type,\n",
    "                    \"parse_date\": datetime.now().isoformat(),\n",
    "                    \"parser_version\": \"2.0.0\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Calculate and add scoring information\n",
    "            parsed_data[\"scoring\"] = self.calculate_parsing_score(parsed_data)\n",
    "            \n",
    "            return parsed_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error parsing resume: {str(e)}\")\n",
    "\n",
    "\n",
    "    def extract_contact_info(self, text: str) -> Dict[str, Optional[str]]:\n",
    "        \"\"\"Extract all contact information.\"\"\"\n",
    "        return {\n",
    "            \"name\": self._extract_name(text) if hasattr(self, '_extract_name') else None,\n",
    "            \"email\": self._extract_email(text) if hasattr(self, '_extract_email') else None,\n",
    "            \"phone\": self._extract_phone(text) if hasattr(self, '_extract_phone') else None,\n",
    "            \"location\": self._extract_location(text) if hasattr(self, '_extract_location') else None,\n",
    "            \"linkedin\": self._extract_linkedin(text) if hasattr(self, '_extract_linkedin') else None,\n",
    "            \"github\": self._extract_github(text) if hasattr(self, '_extract_github') else None,\n",
    "            \"portfolio\": self._extract_portfolio(text)\n",
    "        }\n",
    "\n",
    "    def extract_skills(self, text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extract skills section simply by getting content under Skills header.\"\"\"\n",
    "        skills_section = self._find_section_content(text, [\n",
    "            \"SKILLS\", \"TECHNICAL SKILLS\", \"COMPETENCIES\",\n",
    "            \"EXPERTISE\", \"QUALIFICATIONS\", \"KEY SKILLS\"\n",
    "        ])\n",
    "        \n",
    "        if not skills_section:\n",
    "            return {\"content\": []}\n",
    "            \n",
    "        # Split by lines and clean\n",
    "        skills = [skill.strip() for skill in skills_section.split('\\n') if skill.strip()]\n",
    "        \n",
    "        return {\n",
    "            \"content\": skills\n",
    "        }\n",
    "\n",
    "    def _extract_technical_skills_with_context(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract technical skills with context awareness.\"\"\"\n",
    "        found_skills = set()\n",
    "        \n",
    "        # Check for skills in bullet points or lists\n",
    "        bullet_pattern = r'(?:‚Ä¢|-|\\*|\\d+\\.)\\s*([^‚Ä¢\\n]+)'\n",
    "        bullets = re.finditer(bullet_pattern, text)\n",
    "        for bullet in bullets:\n",
    "            bullet_text = bullet.group(1)\n",
    "            for skill in self.technical_skills[\"programming_languages\"]:\n",
    "                if re.search(rf'\\b{re.escape(skill)}\\b', bullet_text, re.IGNORECASE):\n",
    "                    found_skills.add(skill)\n",
    "        \n",
    "        # Check for skills in context\n",
    "        for category, skills in self.technical_skills.items():\n",
    "            for skill in skills:\n",
    "                # Look for skill mentions with programming context\n",
    "                context_pattern = f\"(?:using|with|in|proficient in|experience in|knowledge of)\\\\s+{re.escape(skill)}\"\n",
    "                if re.search(context_pattern, text, re.IGNORECASE):\n",
    "                    found_skills.add(skill)\n",
    "                \n",
    "                # Look for skill mentions in lists\n",
    "                list_pattern = f\"(?:,|;|\\\\band\\\\b)\\\\s+{re.escape(skill)}\\\\b\"\n",
    "                if re.search(list_pattern, text, re.IGNORECASE):\n",
    "                    found_skills.add(skill)\n",
    "        \n",
    "        return sorted(list(found_skills))\n",
    "\n",
    "    def _extract_soft_skills_with_context(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract soft skills with context awareness.\"\"\"\n",
    "        found_skills = set()\n",
    "        \n",
    "        # Check for skills in bullet points or lists\n",
    "        bullet_pattern = r'(?:‚Ä¢|-|\\*|\\d+\\.)\\s*([^‚Ä¢\\n]+)'\n",
    "        bullets = re.finditer(bullet_pattern, text)\n",
    "        for bullet in bullets:\n",
    "            bullet_text = bullet.group(1)\n",
    "            for category, skills in self.soft_skills.items():\n",
    "                for skill in skills:\n",
    "                    if re.search(rf'\\b{re.escape(skill)}\\b', bullet_text.lower()):\n",
    "                        found_skills.add(skill)\n",
    "        \n",
    "        # Look for skills in context\n",
    "        for category, skills in self.soft_skills.items():\n",
    "            for skill in skills:\n",
    "                # Look for skill mentions with context\n",
    "                context_patterns = [\n",
    "                    rf\"(?:demonstrated|showed|exhibited|possess(?:es)?|strong)\\s+{re.escape(skill)}\",\n",
    "                    rf\"(?:skilled in|proficient in|expertise in)\\s+{re.escape(skill)}\",\n",
    "                    rf\"{re.escape(skill)}(?:\\s+skills?|abilities?|competenc(?:y|ies))\"\n",
    "                ]\n",
    "                \n",
    "                for pattern in context_patterns:\n",
    "                    if re.search(pattern, text.lower()):\n",
    "                        found_skills.add(skill)\n",
    "                \n",
    "                # Look for skill mentions in lists\n",
    "                list_pattern = f\"(?:,|;|\\\\band\\\\b)\\\\s+{re.escape(skill)}\\\\b\"\n",
    "                if re.search(list_pattern, text.lower()):\n",
    "                    found_skills.add(skill)\n",
    "        \n",
    "        return sorted(list(found_skills))\n",
    "\n",
    "    def _extract_tools_with_context(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract tools with context awareness.\"\"\"\n",
    "        found_tools = set()\n",
    "        \n",
    "        # Check for tools in bullet points\n",
    "        bullet_pattern = r'(?:‚Ä¢|-|\\*|\\d+\\.)\\s*([^‚Ä¢\\n]+)'\n",
    "        bullets = re.finditer(bullet_pattern, text)\n",
    "        for bullet in bullets:\n",
    "            bullet_text = bullet.group(1)\n",
    "            for category, tools in self.tools.items():\n",
    "                for tool in tools:\n",
    "                    if re.search(rf'\\b{re.escape(tool)}\\b', bullet_text.lower()):\n",
    "                        found_tools.add(tool)\n",
    "        \n",
    "        # Look for tools with context\n",
    "        for category, tools in self.tools.items():\n",
    "            for tool in tools:\n",
    "                context_patterns = [\n",
    "                    rf\"(?:using|with|in|proficient in|experience with)\\s+{re.escape(tool)}\",\n",
    "                    rf\"{re.escape(tool)}(?:\\s+experience|certified|proficient)\",\n",
    "                    rf\"(?:worked with|familiar with)\\s+{re.escape(tool)}\"\n",
    "                ]\n",
    "                \n",
    "                for pattern in context_patterns:\n",
    "                    if re.search(pattern, text.lower()):\n",
    "                        found_tools.add(tool)\n",
    "        \n",
    "        return sorted(list(found_tools))\n",
    "\n",
    "    def _extract_languages_with_context(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract programming and human languages with context awareness.\"\"\"\n",
    "        found_languages = set()\n",
    "        \n",
    "        # Define language proficiency indicators\n",
    "        proficiency_levels = [\n",
    "            \"native\", \"fluent\", \"proficient\", \"intermediate\", \"basic\",\n",
    "            \"working knowledge\", \"conversational\"\n",
    "        ]\n",
    "        \n",
    "        # Check each language category\n",
    "        for category, langs in {\n",
    "            \"programming\": self.technical_skills[\"programming_languages\"],\n",
    "            \"human\": {\n",
    "                \"english\", \"spanish\", \"french\", \"german\", \"italian\",\n",
    "                \"chinese\", \"japanese\", \"korean\", \"russian\", \"arabic\",\n",
    "                \"indonesian\", \"malay\"\n",
    "            }\n",
    "        }.items():\n",
    "            for lang in langs:\n",
    "                # Look for language with proficiency indicators\n",
    "                for level in proficiency_levels:\n",
    "                    pattern = f\"(?:{re.escape(lang)}\\\\s+{level}|{level}\\\\s+{re.escape(lang)})\"\n",
    "                    if re.search(pattern, text.lower()):\n",
    "                        found_languages.add(lang)\n",
    "                \n",
    "                # Look for language in general context\n",
    "                context_patterns = [\n",
    "                    rf\"(?:proficient in|fluent in|knowledge of)\\s+{re.escape(lang)}\",\n",
    "                    rf\"{re.escape(lang)}(?:\\s+programming|development|coding)\",\n",
    "                    rf\"(?:speak|write|read)\\s+{re.escape(lang)}\"\n",
    "                ]\n",
    "                \n",
    "                for pattern in context_patterns:\n",
    "                    if re.search(pattern, text.lower()):\n",
    "                        found_languages.add(lang)\n",
    "        \n",
    "        return sorted(list(found_languages))\n",
    "\n",
    "    def _extract_frameworks(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract framework skills.\"\"\"\n",
    "        frameworks = {\n",
    "            \"web\": {\n",
    "                \"react\", \"angular\", \"vue\", \"django\", \"flask\", \"spring\",\n",
    "                \"laravel\", \"express\", \"next.js\", \"nuxt.js\", \"gatsby\",\n",
    "                \"ruby on rails\", \"asp.net\", \"symfony\"\n",
    "            },\n",
    "            \"mobile\": {\n",
    "                \"react native\", \"flutter\", \"ionic\", \"xamarin\",\n",
    "                \"android sdk\", \"ios sdk\", \"swift ui\", \"jetpack compose\"\n",
    "            },\n",
    "            \"ml\": {\n",
    "                \"tensorflow\", \"pytorch\", \"keras\", \"scikit-learn\",\n",
    "                \"pandas\", \"numpy\", \"opencv\", \"nltk\"\n",
    "            },\n",
    "            \"testing\": {\n",
    "                \"junit\", \"pytest\", \"jest\", \"mocha\", \"selenium\",\n",
    "                \"cypress\", \"phpunit\", \"rspec\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        found_frameworks = set()\n",
    "        \n",
    "        for category, framework_list in frameworks.items():\n",
    "            for framework in framework_list:\n",
    "                if re.search(rf'\\b{re.escape(framework)}\\b', text.lower()):\n",
    "                    found_frameworks.add(framework)\n",
    "        \n",
    "        return sorted(list(found_frameworks))\n",
    "\n",
    "    def _extract_databases(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract database skills.\"\"\"\n",
    "        databases = {\n",
    "            \"sql\": {\n",
    "                \"mysql\", \"postgresql\", \"sql server\", \"oracle\",\n",
    "                \"sqlite\", \"mariadb\", \"aurora\"\n",
    "            },\n",
    "            \"nosql\": {\n",
    "                \"mongodb\", \"cassandra\", \"redis\", \"dynamodb\",\n",
    "                \"couchdb\", \"firebase\", \"neo4j\"\n",
    "            },\n",
    "            \"search\": {\n",
    "                \"elasticsearch\", \"solr\", \"algolia\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        found_databases = set()\n",
    "        \n",
    "        for category, db_list in databases.items():\n",
    "            for db in db_list:\n",
    "                if re.search(rf'\\b{re.escape(db)}\\b', text.lower()):\n",
    "                    found_databases.add(db)\n",
    "        \n",
    "        return sorted(list(found_databases))\n",
    "\n",
    "    def _extract_methodologies(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract methodology skills.\"\"\"\n",
    "        methodologies = {\n",
    "            \"project_management\": {\n",
    "                \"agile\", \"scrum\", \"kanban\", \"waterfall\", \"lean\",\n",
    "                \"prince2\", \"pmp\", \"itil\"\n",
    "            },\n",
    "            \"development\": {\n",
    "                \"tdd\", \"bdd\", \"ci/cd\", \"devops\", \"microservices\",\n",
    "                \"rest api\", \"soap\", \"mvc\", \"oop\"\n",
    "            },\n",
    "            \"design\": {\n",
    "                \"uml\", \"design patterns\", \"solid principles\",\n",
    "                \"clean architecture\", \"domain driven design\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        found_methodologies = set()\n",
    "        \n",
    "        for category, method_list in methodologies.items():\n",
    "            for method in method_list:\n",
    "                if re.search(rf'\\b{re.escape(method)}\\b', text.lower()):\n",
    "                    found_methodologies.add(method)\n",
    "        \n",
    "        return sorted(list(found_methodologies))\n",
    "\n",
    "# File upload widget creation and handling remains the same...\n",
    "\n",
    "    def _extract_technical_skills(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract technical skills from text.\"\"\"\n",
    "        found_skills = set()\n",
    "        \n",
    "        # Check each category of technical skills\n",
    "        for category, skills in self.technical_skills.items():\n",
    "            for skill in skills:\n",
    "                if re.search(r'\\b' + re.escape(skill) + r'\\b', text.lower()):\n",
    "                    found_skills.add(skill)\n",
    "        \n",
    "        return sorted(list(found_skills))\n",
    "\n",
    "    def _extract_soft_skills(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract soft skills from text.\"\"\"\n",
    "        found_skills = set()\n",
    "        \n",
    "        # Check each category of soft skills\n",
    "        for category, skills in self.soft_skills.items():\n",
    "            for skill in skills:\n",
    "                if re.search(r'\\b' + re.escape(skill) + r'\\b', text.lower()):\n",
    "                    found_skills.add(skill)\n",
    "        \n",
    "        return sorted(list(found_skills))\n",
    "\n",
    "    def _extract_tools(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract tool-related skills.\"\"\"\n",
    "        found_tools = set()\n",
    "        \n",
    "        for category, tools in self.tools.items():\n",
    "            for tool in tools:\n",
    "                if re.search(r'\\b' + re.escape(tool) + r'\\b', text.lower()):\n",
    "                    found_tools.add(tool)\n",
    "        \n",
    "        return sorted(list(found_tools))\n",
    "\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract text from PDF file.\"\"\"\n",
    "        try:\n",
    "            text = \"\"\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "            return self._clean_text(text)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error extracting text from PDF: {str(e)}\")\n",
    "\n",
    "    def extract_text_from_docx(self, docx_path: str) -> str:\n",
    "        \"\"\"Extract text from DOCX file.\"\"\"\n",
    "        try:\n",
    "            doc = Document(docx_path)\n",
    "            text = \"\"\n",
    "            for para in doc.paragraphs:\n",
    "                text += para.text + \"\\n\"\n",
    "            return self._clean_text(text)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error extracting text from DOCX: {str(e)}\")\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and normalize extracted text.\"\"\"\n",
    "        # Remove excessive whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove non-ASCII characters\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "        # Normalize newlines\n",
    "        text = text.replace('\\r', '\\n')\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def _extract_name(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract name from text using NLP.\"\"\"\n",
    "        # Try to find name in first few lines\n",
    "        first_lines = text.split('\\n')[:3]\n",
    "        for line in first_lines:\n",
    "            doc = nlp(line.strip())\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"PERSON\":\n",
    "                    return ent.text.strip()\n",
    "\n",
    "        # Fallback: Look for name in first paragraph\n",
    "        doc = nlp(text[:500])\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                return ent.text.strip()\n",
    "        return None\n",
    "\n",
    "    def _extract_email(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract email address from text.\"\"\"\n",
    "        email_pattern = r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b'\n",
    "        match = re.search(email_pattern, text)\n",
    "        return match.group(0) if match else None\n",
    "\n",
    "    def _extract_phone(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract phone number from text with simpler approach.\"\"\"\n",
    "        # Extract any sequence of digits that looks like a phone number\n",
    "        phone_pattern = r'[\\+\\d\\-\\(\\)\\s\\.]{10,}'\n",
    "        matches = re.findall(phone_pattern, text)\n",
    "        \n",
    "        for match in matches:\n",
    "            # Clean the number to get only digits\n",
    "            digits = ''.join(filter(str.isdigit, match))\n",
    "            # If we have a valid length of digits (10-15 for international numbers)\n",
    "            if 10 <= len(digits) <= 15:\n",
    "                return digits\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _extract_location(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract location information using NLP.\"\"\"\n",
    "        doc = nlp(text[:1000])  # Process first 1000 chars for efficiency\n",
    "        locations = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in [\"GPE\", \"LOC\"]:\n",
    "                locations.append(ent.text)\n",
    "        return ', '.join(locations) if locations else None\n",
    "\n",
    "    def _extract_linkedin(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract LinkedIn profile URL.\"\"\"\n",
    "        patterns = [\n",
    "            r'linkedin\\.com/in/[\\w-]+',\n",
    "            r'linkedin\\.com/profile/[\\w-]+'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text.lower())\n",
    "            if match:\n",
    "                return f\"https://www.{match.group(0)}\"\n",
    "        return None\n",
    "\n",
    "    def _extract_github(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract GitHub profile URL.\"\"\"\n",
    "        match = re.search(r'github\\.com/[\\w-]+', text.lower())\n",
    "        return f\"https://www.{match.group(0)}\" if match else None\n",
    "\n",
    "    def _extract_technical_skills(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract technical skills from text.\"\"\"\n",
    "        found_skills = set()\n",
    "        \n",
    "        # Check each category of technical skills\n",
    "        for category, skills in self.technical_skills.items():\n",
    "            for skill in skills:\n",
    "                if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text.lower()):\n",
    "                    found_skills.add(skill)\n",
    "        \n",
    "        return sorted(list(found_skills))\n",
    "\n",
    "    def _extract_soft_skills(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract soft skills from text.\"\"\"\n",
    "        found_skills = set()\n",
    "        \n",
    "        # Check each category of soft skills\n",
    "        for category, skills in self.soft_skills.items():\n",
    "            for skill in skills:\n",
    "                if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', text.lower()):\n",
    "                    found_skills.add(skill)\n",
    "        \n",
    "        return sorted(list(found_skills))\n",
    "\n",
    "    def _extract_tools(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract tool-related skills.\"\"\"\n",
    "        found_tools = set()\n",
    "        \n",
    "        for category, tools in self.tools.items():\n",
    "            for tool in tools:\n",
    "                if re.search(r'\\b' + re.escape(tool.lower()) + r'\\b', text.lower()):\n",
    "                    found_tools.add(tool)\n",
    "        \n",
    "        return sorted(list(found_tools))\n",
    "\n",
    "    def _extract_languages(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract programming and human languages.\"\"\"\n",
    "        common_languages = {\n",
    "            \"programming\": self.technical_skills[\"programming_languages\"],\n",
    "            \"human\": {\n",
    "                \"english\", \"spanish\", \"french\", \"german\", \"italian\",\n",
    "                \"chinese\", \"japanese\", \"korean\", \"russian\", \"arabic\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        found_languages = set()\n",
    "        for category, langs in common_languages.items():\n",
    "            for lang in langs:\n",
    "                if re.search(r'\\b' + re.escape(lang.lower()) + r'\\b', text.lower()):\n",
    "                    found_languages.add(lang)\n",
    "        \n",
    "        return sorted(list(found_languages))\n",
    "\n",
    "    def _find_section(self, text: str, section_headers: List[str]) -> Optional[str]:\n",
    "        \"\"\"Find and extract a specific section from text with improved recognition.\"\"\"\n",
    "        # Convert text to lines and normalize\n",
    "        lines = [line.strip() for line in text.split('\\n')]\n",
    "        section_content = []\n",
    "        in_section = False\n",
    "        next_section_found = False\n",
    "        \n",
    "        common_section_headers = {\n",
    "            \"EXPERIENCE\": [\"EXPERIENCE\", \"WORK EXPERIENCE\", \"EMPLOYMENT\", \"WORK HISTORY\", \"PROFESSIONAL EXPERIENCE\"],\n",
    "            \"EDUCATION\": [\"EDUCATION\", \"ACADEMIC BACKGROUND\", \"ACADEMIC QUALIFICATIONS\", \"EDUCATIONAL BACKGROUND\"],\n",
    "            \"SKILLS\": [\"SKILLS\", \"TECHNICAL SKILLS\", \"COMPETENCIES\", \"EXPERTISE\", \"QUALIFICATIONS\", \"KEY SKILLS\"],\n",
    "            \"PROJECTS\": [\"PROJECTS\", \"PROJECT EXPERIENCE\", \"KEY PROJECTS\", \"RELEVANT PROJECTS\"],\n",
    "            \"CERTIFICATIONS\": [\"CERTIFICATIONS\", \"CERTIFICATES\", \"PROFESSIONAL CERTIFICATIONS\", \"CREDENTIALS\"]\n",
    "        }\n",
    "        \n",
    "        # Add variations with different cases\n",
    "        for header_group in common_section_headers.values():\n",
    "            header_group.extend([h.lower() for h in header_group])\n",
    "            header_group.extend([h.title() for h in header_group])\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            # Check if line contains section header\n",
    "            current_line = line.lower()\n",
    "            \n",
    "            # Check if this line is a section header we're looking for\n",
    "            is_target_section = any(header.lower() in current_line for header in section_headers)\n",
    "            \n",
    "            # Check if this line is the start of another common section\n",
    "            is_other_section = any(\n",
    "                any(header.lower() in current_line for header in headers)\n",
    "                for headers in common_section_headers.values()\n",
    "            )\n",
    "            \n",
    "            if is_target_section:\n",
    "                in_section = True\n",
    "                continue\n",
    "                \n",
    "            if in_section and is_other_section:\n",
    "                break\n",
    "                \n",
    "            if in_section and line.strip():\n",
    "                # Include line if it's not just a header\n",
    "                if not any(line.lower().strip() == header.lower() for header in sum(common_section_headers.values(), [])):\n",
    "                    section_content.append(line)\n",
    "        \n",
    "        return '\\n'.join(section_content) if section_content else None\n",
    "\n",
    "\n",
    "    def calculate_parsing_metrics(self, parsed_data: Dict) -> Dict[str, float]:\n",
    "        \"\"\"Calculate parsing success metrics.\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Check contact information completeness\n",
    "        contact_fields = [\"name\", \"email\", \"phone\", \"location\", \"linkedin\"]\n",
    "        metrics[\"contact_score\"] = sum(1 for field in contact_fields \n",
    "                                     if parsed_data[\"contact_info\"].get(field)) / len(contact_fields)\n",
    "        \n",
    "        # Check skills extraction\n",
    "        skills_fields = [\"technical\", \"soft\", \"tools\", \"languages\"]\n",
    "        has_skills = [bool(parsed_data[\"skills\"].get(field)) for field in skills_fields]\n",
    "        metrics[\"skills_score\"] = sum(has_skills) / len(skills_fields)\n",
    "        \n",
    "        # Calculate overall confidence score\n",
    "        metrics[\"overall_score\"] = sum(metrics.values()) / len(metrics)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def export_to_json(self, data: Dict, file_path: str):\n",
    "        \"\"\"Export parsed data to JSON.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error exporting to JSON: {str(e)}\")\n",
    "\n",
    "    def export_to_csv(self, data: Dict, file_path: str):\n",
    "        \"\"\"Export parsed data to CSV.\"\"\"\n",
    "        try:\n",
    "            flattened_data = self._flatten_dict(data)\n",
    "            with open(file_path, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=flattened_data.keys())\n",
    "                writer.writeheader()\n",
    "                writer.writerow(flattened_data)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error exporting to CSV: {str(e)}\")\n",
    "\n",
    "    def _flatten_dict(self, d: Dict, parent_key: str = '', sep: str = '_') -> Dict:\n",
    "            \"\"\"Flatten nested dictionary for CSV export.\"\"\"\n",
    "            items = []\n",
    "            for k, v in d.items():\n",
    "                new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "                if isinstance(v, dict):\n",
    "                    items.extend(self._flatten_dict(v, new_key, sep).items())\n",
    "                elif isinstance(v, list):\n",
    "                    items.append((new_key, '; '.join(str(item) for item in v)))\n",
    "                else:\n",
    "                    items.append((new_key, v))\n",
    "            return dict(items)\n",
    "\n",
    "    def extract_experience(self, text: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Extract experience section simply by getting content under Experience header.\"\"\"\n",
    "        experience_section = self._find_section_content(text, [\n",
    "            \"EXPERIENCE\", \"WORK EXPERIENCE\", \"EMPLOYMENT HISTORY\",\n",
    "            \"PROFESSIONAL EXPERIENCE\", \"WORK HISTORY\" \n",
    "        ])\n",
    "        \n",
    "        if not experience_section:\n",
    "            return []\n",
    "            \n",
    "        entries = [entry.strip() for entry in experience_section.split('\\n\\n') if entry.strip()]\n",
    "        experience_list = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            experience_list.append({\n",
    "                \"content\": entry  # Store raw content\n",
    "            })\n",
    "                \n",
    "        return experience_list\n",
    "\n",
    "\n",
    "    def _split_experience_entries(self, text: str) -> List[str]:\n",
    "        \"\"\"Split experience section into individual entries.\"\"\"\n",
    "        # Common patterns that indicate new entries\n",
    "        entry_patterns = [\n",
    "            r'\\b\\d{4}\\s*[-‚Äì‚Äî]\\s*(?:\\d{4}|present|current)\\b',\n",
    "            r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4}\\b'\n",
    "        ]\n",
    "        \n",
    "        # Find all possible entry start positions\n",
    "        splits = []\n",
    "        for pattern in entry_patterns:\n",
    "            splits.extend([(m.start(), m.group()) for m in re.finditer(pattern, text, re.IGNORECASE)])\n",
    "        \n",
    "        # Sort splits by position\n",
    "        splits.sort(key=lambda x: x[0])\n",
    "        \n",
    "        if not splits:\n",
    "            return [text]\n",
    "            \n",
    "        entries = []\n",
    "        for i in range(len(splits)):\n",
    "            start_pos = splits[i][0]\n",
    "            end_pos = splits[i+1][0] if i < len(splits)-1 else len(text)\n",
    "            entries.append(text[start_pos:end_pos].strip())\n",
    "            \n",
    "        return entries\n",
    "\n",
    "    def _extract_company_name(self, text: str) -> str:\n",
    "        \"\"\"Extract company name with improved recognition.\"\"\"\n",
    "        # Common company suffixes\n",
    "        company_suffixes = r'(?:Inc\\.|LLC|Ltd\\.|Corp\\.|Corporation|Company|Co\\.|Group|International|Technologies|Solutions|Systems)'\n",
    "        \n",
    "        # Patterns for company names\n",
    "        patterns = [\n",
    "            # Look for company name after \"at\" or \"for\"\n",
    "            rf'(?:at|@|for)\\s+([A-Z][A-Za-z0-9\\s&,.]{{2,}}(?:{company_suffixes})?)',\n",
    "            \n",
    "            # Look for company name at the start of lines\n",
    "            rf'^([A-Z][A-Za-z0-9\\s&,.]{{2,}}(?:{company_suffixes})?)',\n",
    "            \n",
    "            # Look for all caps company names\n",
    "            r'([A-Z][A-Z\\s&]+[A-Z])',\n",
    "            \n",
    "            # Look for company names with suffixes\n",
    "            rf'([A-Z][A-Za-z0-9\\s&,.]{{2,}}{company_suffixes})'\n",
    "        ]\n",
    "        \n",
    "        # Try each pattern\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                # Clean up the match\n",
    "                company = match.group(1).strip()\n",
    "                # Remove common prefixes/suffixes if they appear alone\n",
    "                company = re.sub(r'^(The|A|An)\\s+', '', company)\n",
    "                return company\n",
    "        \n",
    "        return \"Company Not Specified\"\n",
    "\n",
    "    def _extract_education_degree(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract detailed degree information.\"\"\"\n",
    "        degree_patterns = {\n",
    "            'bachelor': [\n",
    "                r\"Bachelor['']s|B\\.?A\\.?|B\\.?S\\.?|B\\.?E\\.?\",\n",
    "                r\"Bachelor of [A-Za-z\\s]+\",\n",
    "                r\"Sarjana|S1|Strata 1\"\n",
    "            ],\n",
    "            'master': [\n",
    "                r\"Master['']s|M\\.?A\\.?|M\\.?S\\.?|M\\.?E\\.?\",\n",
    "                r\"Master of [A-Za-z\\s]+\",\n",
    "                r\"Magister|S2|Strata 2\"\n",
    "            ],\n",
    "            'phd': [\n",
    "                r\"Ph\\.?D\\.?|Doctor of|Doctorate\",\n",
    "                r\"Doktor|S3|Strata 3\"\n",
    "            ],\n",
    "            'associate': [\n",
    "                r\"Associate['']s|A\\.?A\\.?|A\\.?S\\.?\",\n",
    "                r\"Associate of [A-Za-z\\s]+\"\n",
    "            ],\n",
    "            'diploma': [\n",
    "                r\"Diploma|D3|D4\",\n",
    "                r\"Advanced Diploma\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        degree_info = {\n",
    "            \"level\": None,\n",
    "            \"field\": None,\n",
    "            \"full_name\": None\n",
    "        }\n",
    "        \n",
    "        # Extract degree level and field\n",
    "        for level, patterns in degree_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    degree_info[\"level\"] = level\n",
    "                    # Look for field of study\n",
    "                    field_match = re.search(\n",
    "                        rf\"{pattern}\\s+(?:in|of)?\\s+([A-Za-z\\s&]+?)(?:\\s+(?:from|at|,)|$)\",\n",
    "                        text,\n",
    "                        re.IGNORECASE\n",
    "                    )\n",
    "                    if field_match:\n",
    "                        degree_info[\"field\"] = field_match.group(1).strip()\n",
    "                        degree_info[\"full_name\"] = f\"{match.group(0)} in {degree_info['field']}\"\n",
    "                    break\n",
    "            if degree_info[\"level\"]:\n",
    "                break\n",
    "        \n",
    "        return degree_info\n",
    "\n",
    "    def _extract_institution(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract educational institution with improved recognition.\"\"\"\n",
    "        # Common educational institution keywords\n",
    "        edu_keywords = r'(?:University|College|Institute|School|Academy|Institut|Universitas|Sekolah Tinggi)'\n",
    "        \n",
    "        patterns = [\n",
    "            # Full institution name\n",
    "            rf\"(?:The\\s+)?{edu_keywords}\\s+(?:of\\s+)?[A-Z][A-Za-z\\s&,]+\",\n",
    "            \n",
    "            # Institution with location\n",
    "            rf\"[A-Z][A-Za-z\\s&,]+\\s+{edu_keywords}\",\n",
    "            \n",
    "            # Abbreviated names (e.g., UCLA, MIT)\n",
    "            r\"\\b[A-Z]{2,5}\\b(?=\\s|$|,|\\.|;)\",\n",
    "            \n",
    "            # Indonesian institutions\n",
    "            r\"(?:Institut|Universitas|Sekolah Tinggi)\\s+[A-Z][A-Za-z\\s&,]+\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return match.group(0).strip()\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _extract_gpa(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract GPA/IPK with improved recognition.\"\"\"\n",
    "        patterns = [\n",
    "            # Standard GPA formats\n",
    "            r\"GPA\\s*(?::|of)?\\s*([0-4]\\.\\d{1,2})\",\n",
    "            r\"Grade Point Average\\s*(?::|of)?\\s*([0-4]\\.\\d{1,2})\",\n",
    "            \n",
    "            # IPK formats (Indonesian)\n",
    "            r\"IPK\\s*(?::|of)?\\s*([0-4]\\.\\d{1,2})\",\n",
    "            r\"Indeks Prestasi Kumulatif\\s*(?::|of)?\\s*([0-4]\\.\\d{1,2})\",\n",
    "            \n",
    "            # GPA with scale\n",
    "            r\"GPA\\s*(?::|of)?\\s*(\\d\\.\\d{1,2})/4\\.0\",\n",
    "            r\"IPK\\s*(?::|of)?\\s*(\\d\\.\\d{1,2})/4\\.0\",\n",
    "            \n",
    "            # Variations\n",
    "            r\"(?:cumulative )?GPA:?\\s*([0-4]\\.\\d{1,2})\",\n",
    "            r\"(?:cumulative )?IPK:?\\s*([0-4]\\.\\d{1,2})\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                gpa = float(match.group(1))\n",
    "                if 0 <= gpa <= 4.0:\n",
    "                    return str(gpa)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _extract_job_title(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract job title with improved pattern recognition.\"\"\"\n",
    "        # Look for titles in common formats\n",
    "        title_patterns = [\n",
    "            # Senior level positions\n",
    "            rf\"(?:{'|'.join(self.experience_markers['titles']['senior'])})\\s+\"\n",
    "            rf\"(?:{'|'.join(self.experience_markers['titles']['domains'])})\\s*\"\n",
    "            rf\"(?:{'|'.join(self.experience_markers['titles']['roles'])})\",\n",
    "            \n",
    "            # Standard positions\n",
    "            rf\"(?:{'|'.join(self.experience_markers['titles']['domains'])})\\s*\"\n",
    "            rf\"(?:{'|'.join(self.experience_markers['titles']['roles'])})\",\n",
    "            \n",
    "            # Management positions\n",
    "            r\"(?:Director|VP|Head|Manager|Lead)\\s+(?:of|,)?\\s*[A-Za-z\\s]+\",\n",
    "            \n",
    "            # Other positions\n",
    "            r\"[A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,4}\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in title_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                title = match.group(0).strip()\n",
    "                # Validate title\n",
    "                if len(title.split()) >= 2 and not any(x in title.lower() for x in [\"company\", \"corporation\", \"inc\", \"ltd\"]):\n",
    "                    return title\n",
    "                    \n",
    "        return \"Position Not Specified\"\n",
    "\n",
    "    \n",
    "    def _is_valid_framework(self, skill: str) -> bool:\n",
    "        \"\"\"Validate if a skill is a known framework.\"\"\"\n",
    "        frameworks = {\n",
    "            \"web\": {\"react\", \"angular\", \"vue\", \"django\", \"flask\", \"spring\"},\n",
    "            \"mobile\": {\"react native\", \"flutter\", \"ionic\", \"xamarin\"},\n",
    "            \"testing\": {\"junit\", \"pytest\", \"jest\", \"mocha\", \"selenium\"},\n",
    "            \"ml\": {\"tensorflow\", \"pytorch\", \"keras\", \"scikit-learn\"}\n",
    "        }\n",
    "        return any(skill.lower() in framework_set for framework_set in frameworks.values())\n",
    "\n",
    "    def _is_valid_tool(self, skill: str) -> bool:\n",
    "        \"\"\"Validate if a skill is a known tool.\"\"\"\n",
    "        return skill.lower() in {tool for tools in self.tools.values() for tool in tools}\n",
    "\n",
    "    def _is_valid_database(self, skill: str) -> bool:\n",
    "        \"\"\"Validate if a skill is a known database.\"\"\"\n",
    "        return skill.lower() in self.technical_skills[\"databases\"]\n",
    "\n",
    "    def _is_valid_methodology(self, skill: str) -> bool:\n",
    "        \"\"\"Validate if a skill is a known methodology.\"\"\"\n",
    "        methodologies = {\n",
    "            \"agile\", \"scrum\", \"kanban\", \"waterfall\", \"lean\",\n",
    "            \"devops\", \"tdd\", \"bdd\", \"ci/cd\", \"xp\"\n",
    "        }\n",
    "        return skill.lower() in methodologies\n",
    "\n",
    "    def extract_skills(self, text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extract skills with improved category detection.\"\"\"\n",
    "        skills = {\n",
    "            \"technical\": set(),\n",
    "            \"frameworks\": set(),\n",
    "            \"tools\": set(),\n",
    "            \"databases\": set(),\n",
    "            \"methodologies\": set(),\n",
    "            \"soft\": set(),\n",
    "            \"languages\": set(),\n",
    "            \"cloud\": set()\n",
    "        }\n",
    "        \n",
    "        # Get skills section with expanded headers\n",
    "        skills_section = self._find_section(text, [\n",
    "            \"SKILLS\", \"TECHNICAL SKILLS\", \"CORE COMPETENCIES\",\n",
    "            \"TECHNICAL COMPETENCIES\", \"PROFESSIONAL SKILLS\",\n",
    "            \"KEY SKILLS\", \"EXPERTISE\"\n",
    "        ])\n",
    "        \n",
    "        # If no specific section, use whole text\n",
    "        text_to_analyze = skills_section if skills_section else text\n",
    "        \n",
    "        # Look for skills in context\n",
    "        for category, markers in self.skill_context_markers.items():\n",
    "            # Find text blocks that might contain skills of this category\n",
    "            for marker in markers:\n",
    "                pattern = rf\"{marker}[:\\s]+(.*?)(?=\\n\\n|\\n[A-Z]|$)\"\n",
    "                matches = re.finditer(pattern, text_to_analyze, re.IGNORECASE)\n",
    "                \n",
    "                for match in matches:\n",
    "                    skill_text = match.group(1)\n",
    "                    # Split by common delimiters\n",
    "                    potential_skills = re.split(r'[,;‚Ä¢\\n]|\\s+and\\s+', skill_text)\n",
    "                    \n",
    "                    for skill in potential_skills:\n",
    "                        skill = skill.strip()\n",
    "                        if skill and len(skill) > 1:  # Basic validation\n",
    "                            if category == \"technical\":\n",
    "                                if skill.lower() in self.technical_skills[\"programming_languages\"]:\n",
    "                                    skills[\"technical\"].add(skill)\n",
    "                            elif category == \"frameworks\":\n",
    "                                if self._is_valid_framework(skill):\n",
    "                                    skills[\"frameworks\"].add(skill)\n",
    "                            elif category == \"tools\":\n",
    "                                if self._is_valid_tool(skill):\n",
    "                                    skills[\"tools\"].add(skill)\n",
    "                            elif category == \"databases\":\n",
    "                                if self._is_valid_database(skill):\n",
    "                                    skills[\"databases\"].add(skill)\n",
    "                            elif category == \"methodologies\":\n",
    "                                if self._is_valid_methodology(skill):\n",
    "                                    skills[\"methodologies\"].add(skill)\n",
    "        \n",
    "        # Convert sets to sorted lists\n",
    "        return {k: sorted(list(v)) for k, v in skills.items()}\n",
    "\n",
    "    def _extract_duration(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract job duration.\"\"\"\n",
    "        # Match date patterns\n",
    "        date_pattern = r'(?:(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4})|(?:\\d{4})'\n",
    "        dates = re.findall(date_pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        if not dates:\n",
    "            return {\"start\": \"Unknown\", \"end\": \"Unknown\"}\n",
    "            \n",
    "        return {\n",
    "            \"start\": dates[0],\n",
    "            \"end\": dates[-1] if len(dates) > 1 else \"Present\"\n",
    "        }\n",
    "\n",
    "    def _extract_job_location(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract job location.\"\"\"\n",
    "        # Use spaCy for location detection\n",
    "        doc = nlp(text)\n",
    "        locations = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in [\"GPE\", \"LOC\"]:\n",
    "                locations.append(ent.text)\n",
    "                \n",
    "        return ', '.join(locations) if locations else None\n",
    "\n",
    "    def _extract_responsibilities(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract job responsibilities.\"\"\"\n",
    "        # Split text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        # Keywords that often indicate responsibilities\n",
    "        responsibility_indicators = [\n",
    "            \"responsible for\", \"managed\", \"developed\", \"implemented\",\n",
    "            \"designed\", \"created\", \"led\", \"coordinated\", \"maintained\",\n",
    "            \"built\", \"analyzed\", \"improved\", \"established\"\n",
    "        ]\n",
    "        \n",
    "        responsibilities = []\n",
    "        for sentence in sentences:\n",
    "            # Check if sentence contains responsibility indicators\n",
    "            if any(indicator in sentence.lower() for indicator in responsibility_indicators):\n",
    "                # Clean the sentence\n",
    "                cleaned = sentence.strip()\n",
    "                if cleaned and len(cleaned) > 10:  # Avoid very short phrases\n",
    "                    responsibilities.append(cleaned)\n",
    "                    \n",
    "        return responsibilities\n",
    "\n",
    "    def _extract_achievements_from_experience(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract achievements from job experience.\"\"\"\n",
    "        # Keywords that often indicate achievements\n",
    "        achievement_indicators = [\n",
    "            \"achieved\", \"increased\", \"reduced\", \"improved\", \"awarded\",\n",
    "            \"succeeded\", \"delivered\", \"grew\", \"decreased\", \"saved\",\n",
    "            \"implemented\", \"launched\", \"optimized\"\n",
    "        ]\n",
    "        \n",
    "        # Look for sentences with achievement indicators and metrics\n",
    "        sentences = sent_tokenize(text)\n",
    "        achievements = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if any(indicator in sentence.lower() for indicator in achievement_indicators):\n",
    "                # Look for metrics (numbers with % or other units)\n",
    "                if re.search(r'\\d+(?:\\.\\d+)?%|\\$\\d+|\\d+\\s*(?:million|thousand|users|clients)', sentence):\n",
    "                    achievements.append(sentence.strip())\n",
    "                    \n",
    "        return achievements\n",
    "\n",
    "    def _extract_technologies_used(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract technologies mentioned in experience.\"\"\"\n",
    "        technologies = set()\n",
    "        \n",
    "        # Check for technical skills\n",
    "        for category, skills in self.technical_skills.items():\n",
    "            for skill in skills:\n",
    "                if re.search(r'\\b' + re.escape(skill) + r'\\b', text.lower()):\n",
    "                    technologies.add(skill)\n",
    "                    \n",
    "        # Check for tools\n",
    "        for category, tools in self.tools.items():\n",
    "            for tool in tools:\n",
    "                if re.search(r'\\b' + re.escape(tool) + r'\\b', text.lower()):\n",
    "                    technologies.add(tool)\n",
    "                    \n",
    "        return sorted(list(technologies))\n",
    "\n",
    "    def extract_education(self, text: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Extract education section simply by getting content under Education header.\"\"\"\n",
    "        education_section = self._find_section_content(text, [\n",
    "            \"EDUCATION\", \"ACADEMIC BACKGROUND\", \"ACADEMIC QUALIFICATIONS\",\n",
    "            \"EDUCATIONAL HISTORY\", \"ACADEMIC HISTORY\"\n",
    "        ])\n",
    "        \n",
    "        if not education_section:\n",
    "            return []\n",
    "            \n",
    "        entries = [entry.strip() for entry in education_section.split('\\n\\n') if entry.strip()]\n",
    "        education_list = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            education_list.append({\n",
    "                \"content\": entry  # Store raw content\n",
    "            })\n",
    "        \n",
    "        return education_list\n",
    "\n",
    "\n",
    "    def extract_projects(self, text: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Extract projects section simply by getting content under Projects header.\"\"\"\n",
    "        projects_section = self._find_section_content(text, [\n",
    "            \"PROJECTS\", \"PROJECT EXPERIENCE\", \"KEY PROJECTS\",\n",
    "            \"PERSONAL PROJECTS\", \"PROFESSIONAL PROJECTS\"\n",
    "        ])\n",
    "        \n",
    "        if not projects_section:\n",
    "            return []\n",
    "            \n",
    "        entries = [entry.strip() for entry in projects_section.split('\\n\\n') if entry.strip()]\n",
    "        project_list = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            project_list.append({\n",
    "                \"content\": entry  # Store raw content\n",
    "            })\n",
    "                \n",
    "        return project_list\n",
    "\n",
    "\n",
    "    def extract_certifications(self, text: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Extract certifications section simply by getting content under Certifications header.\"\"\"\n",
    "        certifications_section = self._find_section_content(text, [\n",
    "            \"CERTIFICATIONS\", \"CERTIFICATES\", \"PROFESSIONAL CERTIFICATIONS\",\n",
    "            \"CREDENTIALS\", \"QUALIFICATIONS\", \"ACCREDITATIONS\"\n",
    "        ])\n",
    "        \n",
    "        if not certifications_section:\n",
    "            return []\n",
    "            \n",
    "        entries = [entry.strip() for entry in certifications_section.split('\\n\\n') if entry.strip()]\n",
    "        certification_list = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            certification_list.append({\n",
    "                \"content\": entry  # Store raw content\n",
    "            })\n",
    "                \n",
    "        return certification_list\n",
    "\n",
    "    def _extract_degree(self, text: str) -> str:\n",
    "        \"\"\"Extract degree information.\"\"\"\n",
    "        degree_patterns = [\n",
    "            r\"Bachelor['']?s?\\.?\\s+(?:of|in)\\s+[A-Za-z\\s]+\",\n",
    "            r\"Master['']?s?\\.?\\s+(?:of|in)\\s+[A-Za-z\\s]+\",\n",
    "            r\"Ph\\.?D\\.?\\s+(?:in)?\\s+[A-Za-z\\s]+\",\n",
    "            r\"B\\.?(?:A|S|E)\\.?(?:\\s+in\\s+[A-Za-z\\s]+)?\",\n",
    "            r\"M\\.?(?:A|S|E)\\.?(?:\\s+in\\s+[A-Za-z\\s]+)?\",\n",
    "            r\"(?:Bachelor|Master|Doctor|Ph\\.?D\\.?)\",\n",
    "            r\"(?:S1|S2|S3|D3|D4)\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in degree_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return match.group(0).strip()\n",
    "        return \"Degree Not Found\"\n",
    "\n",
    "    def _extract_field_of_study(self, text: str) -> Optional[str]:\n",
    "        \"\"\"Extract field of study.\"\"\"\n",
    "        field_patterns = [\n",
    "            r\"(?:in|of)\\s+([A-Z][A-Za-z\\s]+?)(?:from|at|,|\\.|$)\",\n",
    "            r\"Major(?:\\s+in)?[:]\\s*([A-Z][A-Za-z\\s]+)\",\n",
    "            r\"Field\\s+of\\s+Study[:]\\s*([A-Z][A-Za-z\\s]+)\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in field_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        return None\n",
    "\n",
    "    def _extract_activities(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract academic activities and achievements.\"\"\"\n",
    "        activities = []\n",
    "        \n",
    "        # Look for activities in bullet points\n",
    "        bullet_pattern = r'(?:‚Ä¢|-|\\*|\\d+\\.)\\s*([^‚Ä¢\\n]+)'\n",
    "        for match in re.finditer(bullet_pattern, text):\n",
    "            activity = match.group(1).strip()\n",
    "            if len(activity) > 10:  # Minimum length to filter noise\n",
    "                activities.append(activity)\n",
    "        \n",
    "        # Look for activities after specific keywords\n",
    "        activity_keywords = [\n",
    "            \"activities\", \"involvement\", \"leadership\",\n",
    "            \"organizations\", \"clubs\", \"societies\"\n",
    "        ]\n",
    "        \n",
    "        for keyword in activity_keywords:\n",
    "            pattern = rf\"{keyword}:?\\s*([^‚Ä¢\\n]+)\"\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                activity = match.group(1).strip()\n",
    "                if len(activity) > 10:\n",
    "                    activities.append(activity)\n",
    "        \n",
    "        return activities\n",
    "\n",
    "    def _split_education_entries(self, text: str) -> List[str]:\n",
    "        \"\"\"Split education section into individual entries.\"\"\"\n",
    "        entries = []\n",
    "        current_entry = []\n",
    "        \n",
    "        # Common patterns that indicate new education entries\n",
    "        education_start_patterns = [\n",
    "            r\"\\b(?:19|20)\\d{2}\\s*[-‚Äì]\\s*(?:19|20)\\d{2}|Present|Current\\b\",\n",
    "            r\"\\b(?:Bachelor|Master|Ph\\.?D|Doctor|S1|S2|S3|D3|D4)\\b\",\n",
    "            r\"\\b(?:University|College|Institute|School)\\b\"\n",
    "        ]\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        for line in lines:\n",
    "            # Check if this line starts a new entry\n",
    "            if any(re.search(pattern, line) for pattern in education_start_patterns):\n",
    "                if current_entry:\n",
    "                    entries.append('\\n'.join(current_entry))\n",
    "                    current_entry = []\n",
    "            if line.strip():\n",
    "                current_entry.append(line.strip())\n",
    "        \n",
    "        # Add the last entry\n",
    "        if current_entry:\n",
    "            entries.append('\\n'.join(current_entry))\n",
    "        \n",
    "        return entries if entries else [text]\n",
    "\n",
    "    def _extract_honors(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract academic honors and awards.\"\"\"\n",
    "        honors = []\n",
    "        \n",
    "        # Common honor keywords and patterns\n",
    "        honor_patterns = [\n",
    "            r\"(?:cum laude|honors|distinction|dean'?s list)\",\n",
    "            r\"(?:first|second|third|highest) class honors\",\n",
    "            r\"(?:gold|silver|bronze) medalist\",\n",
    "            r\"valedictorian|salutatorian\",\n",
    "            r\"summa cum laude|magna cum laude\"\n",
    "        ]\n",
    "        \n",
    "        # Look for honors in text\n",
    "        for pattern in honor_patterns:\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                honor = match.group(0).strip()\n",
    "                # Get surrounding context if available\n",
    "                context_pattern = rf\".{{0,50}}{re.escape(honor)}.{{0,50}}\"\n",
    "                context_match = re.search(context_pattern, text, re.IGNORECASE)\n",
    "                if context_match:\n",
    "                    honor = context_match.group(0).strip()\n",
    "                honors.append(honor)\n",
    "        \n",
    "        return honors\n",
    "\n",
    "    def _extract_education_duration(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Extract education duration.\"\"\"\n",
    "        # Look for year patterns\n",
    "        year_pattern = r\"(?:19|20)\\d{2}\"\n",
    "        years = re.findall(year_pattern, text)\n",
    "        \n",
    "        if not years:\n",
    "            return {\"start\": None, \"end\": None}\n",
    "        \n",
    "        return {\n",
    "            \"start\": min(years),\n",
    "            \"end\": max(years) if len(years) > 1 else \"Present\"\n",
    "        }\n",
    "\n",
    "    def _split_certification_entries(self, text: str) -> List[str]:\n",
    "        \"\"\"Split certification section into individual entries.\"\"\"\n",
    "        entries = []\n",
    "        current_entry = []\n",
    "        \n",
    "        # Patterns that indicate new certification entries\n",
    "        cert_start_patterns = [\n",
    "            r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4}\\b\",\n",
    "            r\"\\b(?:19|20)\\d{2}\\b\",\n",
    "            r\"\\bCertification|Certificate|Certified\\b\"\n",
    "        ]\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        for line in lines:\n",
    "            # Check if this line starts a new entry\n",
    "            if any(re.search(pattern, line, re.IGNORECASE) for pattern in cert_start_patterns):\n",
    "                if current_entry:\n",
    "                    entries.append('\\n'.join(current_entry))\n",
    "                    current_entry = []\n",
    "            if line.strip():\n",
    "                current_entry.append(line.strip())\n",
    "        \n",
    "        # Add the last entry\n",
    "        if current_entry:\n",
    "            entries.append('\\n'.join(current_entry))\n",
    "        \n",
    "        return entries if entries else [text]\n",
    "\n",
    "    def _split_project_entries(self, text: str) -> List[str]:\n",
    "        \"\"\"Split project section into individual entries.\"\"\"\n",
    "        entries = []\n",
    "        current_entry = []\n",
    "        \n",
    "        # Patterns that indicate new project entries\n",
    "        project_start_patterns = [\n",
    "            r\"^(?:[A-Z][A-Za-z0-9\\s]+)(?::|‚Äì|-|\\n)\",\n",
    "            r\"^(?:‚Ä¢|-|\\*)\\s*[A-Z]\",\n",
    "            r\"\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{4}\\b\"\n",
    "        ]\n",
    "        \n",
    "        lines = text.split('\\n')\n",
    "        for line in lines:\n",
    "            # Check if this line starts a new entry\n",
    "            if any(re.search(pattern, line) for pattern in project_start_patterns):\n",
    "                if current_entry:\n",
    "                    entries.append('\\n'.join(current_entry))\n",
    "                    current_entry = []\n",
    "            if line.strip():\n",
    "                current_entry.append(line.strip())\n",
    "        \n",
    "        # Add the last entry\n",
    "        if current_entry:\n",
    "            entries.append('\\n'.join(current_entry))\n",
    "        \n",
    "        return entries if entries else [text]\n",
    "\n",
    "# Tambahkan method-method ini ke dalam class ResumeParser\n",
    "\n",
    "    def _calculate_contact_score(self, contact_info: Dict[str, Any]) -> float:\n",
    "        \"\"\"Calculate score for contact information completeness.\"\"\"\n",
    "        essential_fields = {\"name\": 1.0, \"email\": 1.0, \"phone\": 1.0}\n",
    "        optional_fields = {\"location\": 0.5, \"linkedin\": 0.7, \"github\": 0.3, \"portfolio\": 0.3}\n",
    "        \n",
    "        score = 0.0\n",
    "        max_score = sum(essential_fields.values()) + sum(optional_fields.values())\n",
    "        \n",
    "        for field, weight in essential_fields.items():\n",
    "            if contact_info.get(field):\n",
    "                score += weight\n",
    "        \n",
    "        for field, weight in optional_fields.items():\n",
    "            if contact_info.get(field):\n",
    "                score += weight\n",
    "                \n",
    "        return round((score / max_score) * 100, 2)\n",
    "\n",
    "    def _calculate_experience_score(self, experience: List[Dict[str, Any]]) -> float:\n",
    "        \"\"\"Calculate score for experience section quality.\"\"\"\n",
    "        if not experience:\n",
    "            return 0.0\n",
    "            \n",
    "        max_score_per_entry = 10\n",
    "        scores = []\n",
    "        \n",
    "        for entry in experience:\n",
    "            entry_score = 0\n",
    "            \n",
    "            # Essential components\n",
    "            if entry.get(\"company\"):\n",
    "                entry_score += 2\n",
    "            if entry.get(\"title\"):\n",
    "                entry_score += 2\n",
    "            if entry.get(\"duration\") and entry[\"duration\"].get(\"start\"):\n",
    "                entry_score += 1.5\n",
    "                \n",
    "            # Detail components\n",
    "            if entry.get(\"responsibilities\") and len(entry[\"responsibilities\"]) >= 2:\n",
    "                entry_score += 2\n",
    "            if entry.get(\"achievements\"):\n",
    "                entry_score += 1.5\n",
    "            if entry.get(\"technologies\"):\n",
    "                entry_score += 1\n",
    "                \n",
    "            scores.append(min(entry_score, max_score_per_entry))\n",
    "        \n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        return round((avg_score / max_score_per_entry) * 100, 2)\n",
    "\n",
    "    def _calculate_education_score(self, education: List[Dict[str, Any]]) -> float:\n",
    "        \"\"\"Calculate score for education section quality.\"\"\"\n",
    "        if not education:\n",
    "            return 0.0\n",
    "            \n",
    "        max_score_per_entry = 10\n",
    "        scores = []\n",
    "        \n",
    "        for entry in education:\n",
    "            entry_score = 0\n",
    "            \n",
    "            if entry.get(\"degree\"):\n",
    "                entry_score += 2.5\n",
    "            if entry.get(\"institution\"):\n",
    "                entry_score += 2.5\n",
    "            if entry.get(\"field_of_study\"):\n",
    "                entry_score += 2\n",
    "            if entry.get(\"gpa\"):\n",
    "                entry_score += 1.5\n",
    "            if entry.get(\"honors\"):\n",
    "                entry_score += 1.5\n",
    "                \n",
    "            scores.append(min(entry_score, max_score_per_entry))\n",
    "        \n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        return round((avg_score / max_score_per_entry) * 100, 2)\n",
    "\n",
    "    def _calculate_skills_score(self, skills: Dict[str, List[str]]) -> float:\n",
    "        \"\"\"Calculate score for skills section completeness.\"\"\"\n",
    "        score = 0.0\n",
    "        max_score = 100\n",
    "        \n",
    "        # Check technical skills (40%)\n",
    "        if skills.get(\"technical\"):\n",
    "            tech_score = min(len(skills[\"technical\"]) * 5, 40)\n",
    "            score += tech_score\n",
    "        \n",
    "        # Check soft skills (25%)\n",
    "        if skills.get(\"soft\"):\n",
    "            soft_score = min(len(skills[\"soft\"]) * 5, 25)\n",
    "            score += soft_score\n",
    "        \n",
    "        # Check tools (20%)\n",
    "        if skills.get(\"tools\"):\n",
    "            tools_score = min(len(skills[\"tools\"]) * 4, 20)\n",
    "            score += tools_score\n",
    "        \n",
    "        # Check languages (15%)\n",
    "        if skills.get(\"languages\"):\n",
    "            lang_score = min(len(skills[\"languages\"]) * 3, 15)\n",
    "            score += lang_score\n",
    "        \n",
    "        return round(score, 2)\n",
    "\n",
    "    def _calculate_projects_score(self, projects: List[Dict[str, Any]]) -> float:\n",
    "        \"\"\"Calculate score for projects section quality.\"\"\"\n",
    "        if not projects:\n",
    "            return 0.0\n",
    "            \n",
    "        max_score_per_project = 10\n",
    "        scores = []\n",
    "        \n",
    "        for project in projects:\n",
    "            project_score = 0\n",
    "            \n",
    "            if project.get(\"name\"):\n",
    "                project_score += 2\n",
    "            if project.get(\"description\"):\n",
    "                project_score += 2\n",
    "            if project.get(\"technologies\"):\n",
    "                project_score += 2.5\n",
    "            if project.get(\"url\"):\n",
    "                project_score += 2\n",
    "            if project.get(\"achievements\"):\n",
    "                project_score += 1.5\n",
    "                \n",
    "            scores.append(min(project_score, max_score_per_project))\n",
    "        \n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        return round((avg_score / max_score_per_project) * 100, 2)\n",
    "\n",
    "    def _calculate_certifications_score(self, certifications: List[Dict[str, Any]]) -> float:\n",
    "        \"\"\"Calculate score for certifications section quality.\"\"\"\n",
    "        if not certifications:\n",
    "            return 0.0\n",
    "            \n",
    "        max_score_per_cert = 10\n",
    "        scores = []\n",
    "        \n",
    "        for cert in certifications:\n",
    "            cert_score = 0\n",
    "            \n",
    "            if cert.get(\"name\"):\n",
    "                cert_score += 3\n",
    "            if cert.get(\"issuer\"):\n",
    "                cert_score += 2.5\n",
    "            if cert.get(\"date\"):\n",
    "                cert_score += 2\n",
    "            if cert.get(\"id\"):\n",
    "                cert_score += 1.5\n",
    "            if cert.get(\"validity\"):\n",
    "                cert_score += 1\n",
    "                \n",
    "            scores.append(min(cert_score, max_score_per_cert))\n",
    "        \n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        return round((avg_score / max_score_per_cert) * 100, 2)\n",
    "\n",
    "    def _calculate_formatting_score(self, parsed_data: Dict[str, Any]) -> float:\n",
    "        \"\"\"Calculate score for overall resume formatting and structure.\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        # Check section organization\n",
    "        if parsed_data.get(\"summary\"):\n",
    "            score += 20\n",
    "        \n",
    "        # Check section completeness\n",
    "        essential_sections = [\"contact_info\", \"experience\", \"education\", \"skills\"]\n",
    "        optional_sections = [\"projects\", \"certifications\", \"achievements\"]\n",
    "        \n",
    "        for section in essential_sections:\n",
    "            if parsed_data.get(section):\n",
    "                score += 15\n",
    "                \n",
    "        for section in optional_sections:\n",
    "            if parsed_data.get(section):\n",
    "                score += 5\n",
    "        \n",
    "        return min(round(score, 2), 100)\n",
    "\n",
    "    def _get_score_interpretation(self, scores: Dict[str, float]) -> Dict[str, str]:\n",
    "        \"\"\"Provide interpretation for each score component.\"\"\"\n",
    "        interpretations = {\n",
    "            \"overall\": self._interpret_score(scores[\"overall_score\"], {\n",
    "                90: \"Excellent ATS compatibility\",\n",
    "                80: \"Very good ATS compatibility\",\n",
    "                70: \"Good ATS compatibility\",\n",
    "                60: \"Fair ATS compatibility\",\n",
    "                0: \"Needs improvement for ATS compatibility\"\n",
    "            }),\n",
    "            \"strengths\": [],\n",
    "            \"weaknesses\": []\n",
    "        }\n",
    "        \n",
    "        # Identify strengths and weaknesses\n",
    "        for key, score in scores.items():\n",
    "            if key not in [\"overall_score\", \"interpretation\", \"suggestions\"]:\n",
    "                if score >= 80:\n",
    "                    interpretations[\"strengths\"].append(f\"{key.replace('_score', '').title()}\")\n",
    "                elif score <= 60:\n",
    "                    interpretations[\"weaknesses\"].append(f\"{key.replace('_score', '').title()}\")\n",
    "        \n",
    "        return interpretations\n",
    "\n",
    "    def _interpret_score(self, score: float, thresholds: Dict[int, str]) -> str:\n",
    "        \"\"\"Helper function to interpret scores based on thresholds.\"\"\"\n",
    "        for threshold, interpretation in sorted(thresholds.items(), reverse=True):\n",
    "            if score >= threshold:\n",
    "                return interpretation\n",
    "        return list(thresholds.values())[-1]\n",
    "\n",
    "    def _get_improvement_suggestions(self, scores: Dict[str, float]) -> List[str]:\n",
    "        \"\"\"Generate specific suggestions for improvement based on scores.\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        if scores[\"contact_score\"] < 80:\n",
    "            suggestions.append(\"Add missing essential contact information (name, email, phone)\")\n",
    "        \n",
    "        if scores[\"experience_score\"] < 70:\n",
    "            suggestions.append(\"Include more detailed work responsibilities and achievements\")\n",
    "        \n",
    "        if scores[\"skills_score\"] < 70:\n",
    "            suggestions.append(\"Add more relevant technical and soft skills with clear categorization\")\n",
    "        \n",
    "        if scores[\"education_score\"] < 70:\n",
    "            suggestions.append(\"Provide more details about educational background, including GPA and honors\")\n",
    "        \n",
    "        if scores[\"formatting_score\"] < 60:\n",
    "            suggestions.append(\"Improve overall resume structure and organization\")\n",
    "        \n",
    "        return suggestions\n",
    "\n",
    "    def calculate_parsing_score(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate detailed parsing scores for the resume.\"\"\"\n",
    "        scores = {\n",
    "            \"contact_score\": self._calculate_contact_score(parsed_data.get(\"contact_info\", {})),\n",
    "            \"experience_score\": self._calculate_experience_score(parsed_data.get(\"experience\", [])),\n",
    "            \"education_score\": self._calculate_education_score(parsed_data.get(\"education\", [])),\n",
    "            \"skills_score\": self._calculate_skills_score(parsed_data.get(\"skills\", {})),\n",
    "            \"projects_score\": self._calculate_projects_score(parsed_data.get(\"projects\", [])),\n",
    "            \"certifications_score\": self._calculate_certifications_score(parsed_data.get(\"certifications\", [])),\n",
    "            \"formatting_score\": self._calculate_formatting_score(parsed_data)\n",
    "        }\n",
    "        \n",
    "        # Calculate weighted overall score\n",
    "        weights = {\n",
    "            \"contact_score\": 0.15,\n",
    "            \"experience_score\": 0.25,\n",
    "            \"education_score\": 0.20,\n",
    "            \"skills_score\": 0.20,\n",
    "            \"projects_score\": 0.10,\n",
    "            \"certifications_score\": 0.05,\n",
    "            \"formatting_score\": 0.05\n",
    "        }\n",
    "        \n",
    "        overall_score = sum(scores[key] * weights[key] for key in weights)\n",
    "        scores[\"overall_score\"] = round(overall_score, 2)\n",
    "        \n",
    "        # Add score interpretations\n",
    "        scores[\"interpretation\"] = self._get_score_interpretation(scores)\n",
    "        scores[\"suggestions\"] = self._get_improvement_suggestions(scores)\n",
    "        \n",
    "        return scores\n",
    "\n",
    "def display_parsed_data(parsed_data: Dict[str, Any]):\n",
    "    \"\"\"Display parsed data in a more attractive format.\"\"\"\n",
    "    def print_section(title, content=None):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"{title.upper():^50}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        if content:\n",
    "            print(content)\n",
    "\n",
    "\n",
    "\n",
    "    def print_contact_info(info):\n",
    "        if not info:\n",
    "            return\n",
    "        \n",
    "        print(\"üìû Contact Information:\")\n",
    "        print(\"-\" * 30)\n",
    "        fields = {\n",
    "            \"name\": \"üë§ Name\",\n",
    "            \"email\": \"üìß Email\",\n",
    "            \"phone\": \"üì± Phone\",\n",
    "            \"location\": \"üìç Location\",\n",
    "            \"linkedin\": \"üíº LinkedIn\",\n",
    "            \"github\": \"üíª GitHub\",\n",
    "            \"portfolio\": \"üåê Portfolio\"\n",
    "        }\n",
    "        \n",
    "        for key, label in fields.items():\n",
    "            if info.get(key):\n",
    "                print(f\"{label}: {info[key]}\")\n",
    "\n",
    "    def print_skills(skills):\n",
    "        if not skills:\n",
    "            return\n",
    "            \n",
    "        print(\"üîß Skills:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        categories = {\n",
    "            \"technical\": \"üíª Technical\",\n",
    "            \"soft\": \"ü§ù Soft Skills\",\n",
    "            \"tools\": \"üõ† Tools\",\n",
    "            \"languages\": \"üó£ Languages\"\n",
    "        }\n",
    "        \n",
    "        for category, label in categories.items():\n",
    "            if skills.get(category):\n",
    "                print(f\"\\n{label}:\")\n",
    "                print(\", \".join(skills[category]))\n",
    "\n",
    "    def print_experience(experience):\n",
    "        if not experience:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüíº Work Experience:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for job in experience:\n",
    "            print(f\"\\nüè¢ {job.get('company', 'Unknown Company')}\")\n",
    "            print(f\"üìã {job.get('title', 'Unknown Position')}\")\n",
    "            if job.get('duration'):\n",
    "                print(f\"üìÖ {job['duration'].get('start', 'Unknown')} - {job['duration'].get('end', 'Present')}\")\n",
    "            if job.get('location'):\n",
    "                print(f\"üìç {job['location']}\")\n",
    "            \n",
    "            if job.get('responsibilities'):\n",
    "                print(\"\\nKey Responsibilities:\")\n",
    "                for resp in job['responsibilities'][:3]:  # Show top 3\n",
    "                    print(f\"‚Ä¢ {resp}\")\n",
    "            \n",
    "            if job.get('technologies'):\n",
    "                print(f\"\\nTechnologies: {', '.join(job['technologies'])}\")\n",
    "                \n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    def print_education(education):\n",
    "        if not education:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüéì Education:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for edu in education:\n",
    "            if edu.get('institution'):\n",
    "                print(f\"\\nüìö {edu['institution']}\")\n",
    "            if edu.get('degree'):\n",
    "                print(f\"üéØ {edu['degree']}\")\n",
    "            if edu.get('field_of_study'):\n",
    "                print(f\"üìñ {edu['field_of_study']}\")\n",
    "            if edu.get('gpa'):\n",
    "                print(f\"üèÜ GPA: {edu['gpa']}\")\n",
    "            if edu.get('honors'):\n",
    "                print(f\"üåü Honors: {', '.join(edu['honors'])}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    def print_certifications(certifications):\n",
    "        if not certifications:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüìú Certifications:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for cert in certifications:\n",
    "            print(f\"\\n‚úÖ {cert.get('name', 'Unknown Certification')}\")\n",
    "            if cert.get('issuer'):\n",
    "                print(f\"üè¢ Issuer: {cert['issuer']}\")\n",
    "            if cert.get('date'):\n",
    "                print(f\"üìÖ Date: {cert['date']}\")\n",
    "            if cert.get('id'):\n",
    "                print(f\"üîë ID: {cert['id']}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    def print_projects(projects):\n",
    "        if not projects:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüöÄ Projects:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for project in projects:\n",
    "            print(f\"\\nüì± {project.get('name', 'Unknown Project')}\")\n",
    "            if project.get('description'):\n",
    "                print(f\"\\nüìù {project['description'][:200]}...\")\n",
    "            if project.get('technologies'):\n",
    "                print(f\"\\nüíª Technologies: {', '.join(project['technologies'])}\")\n",
    "            if project.get('url'):\n",
    "                print(f\"üîó URL: {project['url']}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    # Print all sections\n",
    "    print(\"\\nüìÑ RESUME PARSING RESULTS üìÑ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print_contact_info(parsed_data.get('contact_info'))\n",
    "    \n",
    "    if parsed_data.get('summary'):\n",
    "        print_section(\"Summary\", parsed_data['summary'])\n",
    "    \n",
    "    print_skills(parsed_data.get('skills'))\n",
    "    print_experience(parsed_data.get('experience'))\n",
    "    print_education(parsed_data.get('education'))\n",
    "    print_certifications(parsed_data.get('certifications'))\n",
    "    print_projects(parsed_data.get('projects'))\n",
    "    \n",
    "    if parsed_data.get('achievements'):\n",
    "        print_section(\"Achievements\", \"\\n\".join(f\"üèÜ {achievement}\" for achievement in parsed_data['achievements']))\n",
    "\n",
    "    # Print parsing metrics if available\n",
    "    if parsed_data.get('metadata'):\n",
    "        print(f\"\\nüìä Parsing Metrics:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"üìÖ Parse Date: {parsed_data['metadata'].get('parse_date', 'Unknown')}\")\n",
    "        print(f\"üìÅ File Type: {parsed_data['metadata'].get('file_type', 'Unknown')}\")\n",
    "        print(f\"üîÑ Parser Version: {parsed_data['metadata'].get('parser_version', 'Unknown')}\")\n",
    "\n",
    "# Fungsi untuk menampilkan hasil parsing dan scoring\n",
    "def on_file_upload(change):\n",
    "    \"\"\"Handle file upload and parsing with beautiful output.\"\"\"\n",
    "    try:\n",
    "        file_upload = change['owner']\n",
    "        \n",
    "        if not file_upload.value:\n",
    "            print(\"‚ùå No file uploaded\")\n",
    "            return\n",
    "            \n",
    "        # Get uploaded file\n",
    "        uploaded_file = file_upload.value[0]\n",
    "        file_name = uploaded_file.name\n",
    "        file_content = uploaded_file.content\n",
    "        file_path = f\"./{file_name}\"\n",
    "        \n",
    "        print(f\"üìÇ Processing file: {file_name}\")\n",
    "        \n",
    "        # Save file\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(file_content)\n",
    "        \n",
    "        # Determine file type and parse\n",
    "        file_type = \"pdf\" if file_name.lower().endswith(\".pdf\") else \"docx\"\n",
    "        parser = ResumeParser()\n",
    "        parsed_data = parser.parse_resume(file_path, file_type)\n",
    "        \n",
    "        # Generate output files\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        \n",
    "        # Export to JSON\n",
    "        json_path = f\"{base_name}_{timestamp}_parsed.json\"\n",
    "        parser.export_to_json(parsed_data, json_path)\n",
    "        \n",
    "        # Export to CSV\n",
    "        csv_path = f\"{base_name}_{timestamp}_parsed.csv\"\n",
    "        parser.export_to_csv(parsed_data, csv_path)\n",
    "        \n",
    "        # Display results using the new display functions\n",
    "        display_parsed_data(parsed_data)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Results exported to:\")\n",
    "        print(f\"üìÑ JSON: {json_path}\")\n",
    "        print(f\"üìÑ CSV: {csv_path}\")\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing file: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def display_parsed_data(parsed_data: Dict[str, Any]):\n",
    "    \"\"\"Display parsed data in a more attractive format.\"\"\"\n",
    "    def print_section(title, content=None):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"{title.upper():^50}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        if content:\n",
    "            print(content)\n",
    "\n",
    "    def print_contact_info(info):\n",
    "        if not info:\n",
    "            return\n",
    "        \n",
    "        print(\"üìû Contact Information:\")\n",
    "        print(\"-\" * 30)\n",
    "        fields = {\n",
    "            \"name\": \"üë§ Name\",\n",
    "            \"email\": \"üìß Email\",\n",
    "            \"phone\": \"üì± Phone\",\n",
    "            \"location\": \"üìç Location\",\n",
    "            \"linkedin\": \"üíº LinkedIn\",\n",
    "            \"github\": \"üíª GitHub\",\n",
    "            \"portfolio\": \"üåê Portfolio\"\n",
    "        }\n",
    "        \n",
    "        for key, label in fields.items():\n",
    "            if info.get(key):\n",
    "                print(f\"{label}: {info[key]}\")\n",
    "\n",
    "    def print_skills(skills):\n",
    "        if not skills:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüîß Skills:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        categories = {\n",
    "            \"technical\": \"üíª Technical\",\n",
    "            \"soft\": \"ü§ù Soft Skills\",\n",
    "            \"tools\": \"üõ† Tools\",\n",
    "            \"languages\": \"üó£ Languages\"\n",
    "        }\n",
    "        \n",
    "        for category, label in categories.items():\n",
    "            if skills.get(category):\n",
    "                print(f\"\\n{label}:\")\n",
    "                print(\", \".join(skills[category]))\n",
    "\n",
    "    def print_experience(experience):\n",
    "        if not experience:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüíº Work Experience:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for job in experience:\n",
    "            print(f\"\\nüè¢ {job.get('company', 'Unknown Company')}\")\n",
    "            print(f\"üìã {job.get('title', 'Unknown Position')}\")\n",
    "            if job.get('duration'):\n",
    "                print(f\"üìÖ {job['duration'].get('start', 'Unknown')} - {job['duration'].get('end', 'Present')}\")\n",
    "            if job.get('location'):\n",
    "                print(f\"üìç {job['location']}\")\n",
    "            \n",
    "            if job.get('responsibilities'):\n",
    "                print(\"\\nKey Responsibilities:\")\n",
    "                for resp in job['responsibilities'][:3]:  # Show top 3\n",
    "                    print(f\"‚Ä¢ {resp}\")\n",
    "            \n",
    "            if job.get('technologies'):\n",
    "                print(f\"\\nTechnologies: {', '.join(job['technologies'])}\")\n",
    "                \n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    def print_education(education):\n",
    "        if not education:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüéì Education:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for edu in education:\n",
    "            if edu.get('institution'):\n",
    "                print(f\"\\nüìö {edu['institution']}\")\n",
    "            if edu.get('degree'):\n",
    "                print(f\"üéØ {edu['degree']}\")\n",
    "            if edu.get('field_of_study'):\n",
    "                print(f\"üìñ {edu['field_of_study']}\")\n",
    "            if edu.get('gpa'):\n",
    "                print(f\"üèÜ GPA: {edu['gpa']}\")\n",
    "            if edu.get('honors'):\n",
    "                print(f\"üåü Honors: {', '.join(edu['honors'])}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    def print_certifications(certifications):\n",
    "        if not certifications:\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüìú Certifications:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for cert in certifications:\n",
    "            print(f\"\\n‚úÖ {cert.get('name', 'Unknown Certification')}\")\n",
    "            if cert.get('issuer'):\n",
    "                print(f\"üè¢ Issuer: {cert['issuer']}\")\n",
    "            if cert.get('date'):\n",
    "                print(f\"üìÖ Date: {cert['date']}\")\n",
    "            if cert.get('id'):\n",
    "                print(f\"üîë ID: {cert['id']}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    # Print all sections\n",
    "    print(\"\\nüìÑ RESUME PARSING RESULTS üìÑ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print_contact_info(parsed_data.get('contact_info'))\n",
    "    \n",
    "    if parsed_data.get('summary'):\n",
    "        print_section(\"Summary\", parsed_data['summary'])\n",
    "    \n",
    "    print_skills(parsed_data.get('skills'))\n",
    "    print_experience(parsed_data.get('experience'))\n",
    "    print_education(parsed_data.get('education'))\n",
    "    print_certifications(parsed_data.get('certifications'))\n",
    "    \n",
    "    if parsed_data.get('achievements'):\n",
    "        print_section(\"Achievements\", \"\\n\".join(f\"üèÜ {achievement}\" for achievement in parsed_data['achievements']))\n",
    "\n",
    "    # Display scoring results if available\n",
    "    if parsed_data.get('scoring'):\n",
    "        display_scoring_results(parsed_data[\"scoring\"])\n",
    "\n",
    "def display_scoring_results(scores: Dict[str, Any]):\n",
    "    \"\"\"Display parsing scores in a visually appealing format.\"\"\"\n",
    "    print(\"\\nüìä ATS COMPATIBILITY SCORING üìä\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display overall score with visual meter\n",
    "    overall_score = scores[\"overall_score\"]\n",
    "    print(f\"\\nüéØ Overall ATS Compatibility Score: {overall_score}%\")\n",
    "    meter_length = 40\n",
    "    filled = int((overall_score / 100) * meter_length)\n",
    "    meter = \"‚ñà\" * filled + \"‚ñí\" * (meter_length - filled)\n",
    "    print(f\"[{meter}]\")\n",
    "    \n",
    "    # Display individual scores\n",
    "    print(\"\\nüìà Detailed Scores:\")\n",
    "    print(\"-\" * 50)\n",
    "    components = [\n",
    "        (\"üë§ Contact Information\", \"contact_score\"),\n",
    "        (\"üíº Work Experience\", \"experience_score\"),\n",
    "        (\"üéì Education\", \"education_score\"),\n",
    "        (\"üîß Skills\", \"skills_score\"),\n",
    "        (\"üöÄ Projects\", \"projects_score\"),\n",
    "        (\"üìú Certifications\", \"certifications_score\"),\n",
    "        (\"üìã Formatting\", \"formatting_score\")\n",
    "    ]\n",
    "    \n",
    "    for label, key in components:\n",
    "        score = scores.get(key, 0)\n",
    "        filled = int((score / 100) * 20)\n",
    "        meter = \"‚ñà\" * filled + \"‚ñí\" * (20 - filled)\n",
    "        print(f\"{label}: {score}% [{meter}]\")\n",
    "    \n",
    "    # Display interpretation\n",
    "    print(\"\\nüéØ Score Interpretation:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Overall: {scores['interpretation']['overall']}\")\n",
    "    \n",
    "    if scores['interpretation']['strengths']:\n",
    "        print(\"\\nüí™ Strengths:\")\n",
    "        for strength in scores['interpretation']['strengths']:\n",
    "            print(f\"‚úì {strength}\")\n",
    "    \n",
    "    if scores['interpretation']['weaknesses']:\n",
    "        print(\"\\nüîç Areas for Improvement:\")\n",
    "        for weakness in scores['interpretation']['weaknesses']:\n",
    "            print(f\"‚Ä¢ {weakness}\")\n",
    "    \n",
    "    # Display suggestions\n",
    "    if scores['suggestions']:\n",
    "        print(\"\\nüí° Improvement Suggestions:\")\n",
    "        print(\"-\" * 50)\n",
    "        for suggestion in scores['suggestions']:\n",
    "            print(f\"‚ñ∫ {suggestion}\")\n",
    "\n",
    "# Create upload widget with better styling\n",
    "file_upload_widget = FileUpload(\n",
    "    accept='.pdf, .docx',\n",
    "    multiple=False,\n",
    "    description='üìé Upload Resume'\n",
    ")\n",
    "file_upload_widget.observe(on_file_upload, names='value')\n",
    "display(file_upload_widget)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
